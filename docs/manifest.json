{
  "name": "Jiva",
  "root_path": "/Users/abidev/dev/Jiva",
  "primary_language": "Python",
  "frameworks": [
    "Playwright",
    "aiohttp",
    "BeautifulSoup",
    "Google Search API",
    "Markdownify",
    "Logging",
    "Asynchronous Programming",
    "asyncio for asynchronous operations",
    "asyncio",
    "FastAPI",
    "Uvicorn",
    "None (This is a license, not a code)",
    "unittest.mock",
    "tenacity",
    "asyncio for asynchronous programming",
    "logging for operational logging",
    "json for serialization/deserialization of data",
    "os for file operations",
    "async_await",
    "logging",
    "abstractmethod",
    "priority_queue_usage",
    "Docker",
    "FastAPI for building APIs",
    "Uvicorn as an ASGI server for FastAPI",
    "pytest for testing",
    "pandas for data manipulation",
    "click for building command line interfaces",
    "aiohttp for handling async HTTP requests",
    "python-dotenv for environment variable management",
    "YAML configuration format",
    "Docker Compose",
    "abc module for abstract classes",
    "Python",
    "Qdrant vector database",
    "Ollama for LLM management",
    "asyncio (for async functionality)",
    "asyncio (Python's standard library for asynchronous programming)"
  ],
  "files": {
    "actions/web_interface.py": {
      "path": "actions/web_interface.py",
      "language": "Python",
      "purpose": "This code provides a web interface for performing asynchronous web searches, visiting web pages, and extracting relevant content using a language model, as well as finding links on web pages.",
      "exposures": [
        {
          "name": "set_llm_interface",
          "type": "exposure",
          "file_path": "actions/web_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "web_search",
          "type": "exposure",
          "file_path": "actions/web_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "visit_page",
          "type": "exposure",
          "file_path": "actions/web_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "extract_relevant_content",
          "type": "exposure",
          "file_path": "actions/web_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "find_links",
          "type": "exposure",
          "file_path": "actions/web_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": [
            "actions/file_operations.py",
            "main.py",
            "core/memory.py",
            "llm_providers/anthropic_provider.py",
            "core/llm_interface.py",
            "llm_providers/ollama_provider.py",
            "llm_providers/base_provider.py",
            "actions/memory_retrieval.py",
            "core/sensor_manager.py",
            "llm_providers/mistral_ai_provider.py",
            "sensors/sensor_base.py",
            "llm_providers/openai_provider.py",
            "sensors/chat_interface.py",
            "actions/think.py",
            "core/action_manager.py"
          ]
        },
        {
          "name": "bs4",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "playwright",
          "type": "external",
          "version": null,
          "used_by": [
            "requirements.txt"
          ]
        },
        {
          "name": "aiohttp",
          "type": "external",
          "version": null,
          "used_by": [
            "llm_providers/anthropic_provider.py",
            "llm_providers/ollama_provider.py"
          ]
        },
        {
          "name": "googlesearch",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "markdownify",
          "type": "external",
          "version": null,
          "used_by": [
            "requirements.txt"
          ]
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": [
            "actions/file_operations.py",
            "main.py",
            "core/memory.py",
            "core/llm_interface.py",
            "core/ethical_framework.py",
            "core/agent.py",
            "utils/qdrant_handler.py",
            "core/task_manager.py",
            "api/main.py",
            "core/action_manager.py"
          ]
        },
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": [
            "actions/file_operations.py",
            "main.py",
            "core/agent.py",
            "core/sensor_manager.py",
            "api/main.py",
            "sensors/chat_interface.py",
            "actions/think.py"
          ]
        },
        {
          "name": "core.llm_interface",
          "type": "external",
          "version": null,
          "used_by": [
            "actions/think.py"
          ]
        }
      ],
      "elements": [
        {
          "name": "logger",
          "type": "variable",
          "file_path": "actions/web_interface.py",
          "line_number": 12,
          "scope": "module",
          "purpose": "Logger for logging error and debug messages.",
          "documentation": "Created using logging.getLogger(__name__), this logger is used to log errors and other messages within the module."
        },
        {
          "name": "llm_interface",
          "type": "variable",
          "file_path": "actions/web_interface.py",
          "line_number": 13,
          "scope": "module",
          "purpose": "Global variable to hold a reference to the LLMInterface object.",
          "documentation": "Initialized as None, this variable is set by the set_llm_interface function to use the LLM for content extraction."
        },
        {
          "name": "set_llm_interface",
          "type": "function",
          "file_path": "actions/web_interface.py",
          "line_number": 15,
          "scope": "module",
          "purpose": "Sets the LLMInterface instance for use in the module.",
          "documentation": "Sets a global llm_interface variable to an LLMInterface instance provided as an argument."
        },
        {
          "name": "web_search",
          "type": "function",
          "file_path": "actions/web_interface.py",
          "line_number": 20,
          "scope": "module",
          "purpose": "Performs a web search and retrieves details like title, description, and relevant content for each result.",
          "documentation": "Makes use of Google search and aiohttp to asynchronously fetch and parse the web pages, extracting relevant content with LLM assistance."
        },
        {
          "name": "visit_page",
          "type": "function",
          "file_path": "actions/web_interface.py",
          "line_number": 66,
          "scope": "module",
          "purpose": "Visits a web page and returns its content as markdown.",
          "documentation": "Leverages playwright to open the page, convert its HTML content to markdown using markdownify, and return the result."
        },
        {
          "name": "extract_relevant_content",
          "type": "function",
          "file_path": "actions/web_interface.py",
          "line_number": 94,
          "scope": "module",
          "purpose": "Uses the LLM to extract the most relevant content from a markdown-converted page based on the search query.",
          "documentation": "Constructs a prompt using the web page content and query, then uses LLM to generate a relevant summary in markdown."
        },
        {
          "name": "find_links",
          "type": "function",
          "file_path": "actions/web_interface.py",
          "line_number": 118,
          "scope": "module",
          "purpose": "Finds and returns links available on a given web page.",
          "documentation": "Uses playwright to navigate the page and evaluate JavaScript to gather a list of all anchor tags and their href attributes."
        }
      ],
      "framework_hints": [
        "Playwright",
        "aiohttp",
        "BeautifulSoup",
        "Google Search API",
        "Markdownify",
        "Logging",
        "Asynchronous Programming"
      ],
      "last_modified": "2025-02-08T21:04:31.345394",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing",
          "bs4",
          "playwright",
          "aiohttp",
          "googlesearch",
          "markdownify",
          "logging",
          "asyncio",
          "core.llm_interface"
        ],
        "imported_by": []
      }
    },
    "config.json": {
      "path": "config.json",
      "language": "Unknown",
      "purpose": "Configuration file for a software system that integrates with memory storage, language models, and other operational parameters.",
      "exposures": [
        {
          "name": "qdrant_host",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "qdrant_port",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "collection_name",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "max_short_term_memory",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "vector_size",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "provider",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "api_base_url",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "model",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "api_key",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "max_retries",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "timeout",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "enabled",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "awake_duration",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "sleep_duration",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "principles",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "prompt",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "memory_consolidation_threshold",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "agent_loop_delay",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "goals",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "schedule",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "last_run",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "validation",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "task_plan",
          "type": "exposure",
          "file_path": "config.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [],
      "elements": [
        {
          "name": "memory",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 2,
          "scope": "global",
          "purpose": "Configuration settings for memory storage and management using Qdrant.",
          "documentation": "Contains settings for connecting to a Qdrant instance, including host, port, collection name, and memory limits."
        },
        {
          "name": "llm",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 9,
          "scope": "global",
          "purpose": "Configuration for a large language model service from OpenAI.",
          "documentation": "Defines the provider, API details, model type, API key, retry and timeout settings for interactions with OpenAI's LLM."
        },
        {
          "name": "sleep_cycle",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 17,
          "scope": "global",
          "purpose": "Configuration related to the system's sleep and awake cycles.",
          "documentation": "Controls whether the system uses sleep cycles, and sets duration for awake and sleep intervals."
        },
        {
          "name": "mistral-llm",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 23,
          "scope": "global",
          "purpose": "Configuration for a large language model service from Mistral AI.",
          "documentation": "Similar configuration as 'llm' but targeted for Mistral AI's model services."
        },
        {
          "name": "ethical_framework",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 30,
          "scope": "global",
          "purpose": "Specifies the ethical guidelines the agent should follow.",
          "documentation": "Defines principles for ethical decision-making, can be enabled or disabled."
        },
        {
          "name": "sensors",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 38,
          "scope": "global",
          "purpose": "Configuration for sensors, particularly a chat interface.",
          "documentation": "Currently defines settings for a chat interface prompt."
        },
        {
          "name": "memory_consolidation_threshold",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 42,
          "scope": "global",
          "purpose": "Control for when memory consolidation should occur.",
          "documentation": "Threshold setting to determine when consolidation of short-term memory spikes should happen."
        },
        {
          "name": "actions",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 43,
          "scope": "global",
          "purpose": "Placeholder for action configurations.",
          "documentation": "Currently empty, likely intended for storing actionable configurations or commands."
        },
        {
          "name": "agent_loop_delay",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 44,
          "scope": "global",
          "purpose": "Sets delay intervals for the agent's operational loop.",
          "documentation": "Determines the waiting period between action loop iterations for the agent."
        },
        {
          "name": "awake_duration",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 45,
          "scope": "global",
          "purpose": "Defines length of time the agent remains awake.",
          "documentation": "Seconds for which the agent will be active before a sleep cycle. Possible overlap with sleep_cycle configuration."
        },
        {
          "name": "sleep_duration",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 46,
          "scope": "global",
          "purpose": "Defines length of time the agent remains dormant.",
          "documentation": "Seconds for which the agent will remain inoperative. Possible overlap with sleep_cycle configuration."
        },
        {
          "name": "scheduler",
          "type": "variable",
          "file_path": "config.json",
          "line_number": 47,
          "scope": "global",
          "purpose": "Manages scheduled tasks for the agent, including goals and their execution schedules.",
          "documentation": "Currently, a task is scheduled to ensure a greeting file is updated every minute."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:04:51.640444",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [],
        "imported_by": []
      }
    },
    "actions/file_operations.py": {
      "path": "actions/file_operations.py",
      "language": "Python",
      "purpose": "The code provides various asynchronous file operations, including reading, writing, appending, and deleting files and directories, as well as handling JSON and CSV file formats.",
      "exposures": [
        {
          "name": "expand_user_path",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "ensure_directory_exists",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "read_file",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "write_file",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "append_file",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "delete_file",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "list_directory",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "create_directory",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "read_json",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "write_json",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "read_csv",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "write_csv",
          "type": "exposure",
          "file_path": "actions/file_operations.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "os",
          "type": "external",
          "version": null,
          "used_by": [
            "main.py",
            "core/agent.py"
          ]
        },
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": [
            "main.py",
            "core/memory.py",
            "llm_providers/anthropic_provider.py",
            "core/llm_interface.py",
            "core/agent.py",
            "llm_providers/ollama_provider.py",
            "models/embeddings.py"
          ]
        },
        {
          "name": "csv",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "expand_user_path",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 8,
          "scope": "global",
          "purpose": "Expands a user's home directory symbol to a full path.",
          "documentation": "Expand a user's home directory symbol (e.g., '~/') to a full path, or return the original path if it's a simple filename."
        },
        {
          "name": "ensure_directory_exists",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 18,
          "scope": "global",
          "purpose": "Ensures that the directory for a given file path exists, creating it if necessary.",
          "documentation": "Ensure that the directory for the given file path exists. Creates directories if they do not exist."
        },
        {
          "name": "read_file",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 27,
          "scope": "global",
          "purpose": "Asynchronously reads and returns the content of a file.",
          "documentation": "Read and return the contents of a file."
        },
        {
          "name": "write_file",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 46,
          "scope": "global",
          "purpose": "Asynchronously writes content to a file, creating the file if it does not exist.",
          "documentation": "Write the given content to a file. Creates the file if it does not exist."
        },
        {
          "name": "append_file",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 68,
          "scope": "global",
          "purpose": "Asynchronously appends content to an existing file.",
          "documentation": "Append the given content to the end of a file if the file already exists."
        },
        {
          "name": "delete_file",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 87,
          "scope": "global",
          "purpose": "Asynchronously deletes a specified file.",
          "documentation": "Delete the specified file."
        },
        {
          "name": "list_directory",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 104,
          "scope": "global",
          "purpose": "Asynchronously lists all contents of a specified directory.",
          "documentation": "List all contents of the specified directory."
        },
        {
          "name": "create_directory",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 125,
          "scope": "global",
          "purpose": "Asynchronously creates a new directory at the specified path.",
          "documentation": "Create a new directory at the specified path."
        },
        {
          "name": "read_json",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 143,
          "scope": "global",
          "purpose": "Asynchronously reads a JSON file and returns its contents as a dictionary.",
          "documentation": "Read a JSON file and return its contents as a dictionary."
        },
        {
          "name": "write_json",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 167,
          "scope": "global",
          "purpose": "Asynchronously writes a dictionary to a JSON file.",
          "documentation": "Write the given data to a JSON file."
        },
        {
          "name": "read_csv",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 189,
          "scope": "global",
          "purpose": "Asynchronously reads a CSV file and returns its contents as a list of dictionaries.",
          "documentation": "Read a CSV file and return its contents as a list of dictionaries."
        },
        {
          "name": "write_csv",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 217,
          "scope": "global",
          "purpose": "Asynchronously writes a list of dictionaries to a CSV file.",
          "documentation": "Write a list of dictionaries to a CSV file."
        },
        {
          "name": "main",
          "type": "function",
          "file_path": "actions/file_operations.py",
          "line_number": 240,
          "scope": "global",
          "purpose": "Main entry point for testing the asynchronous functions.",
          "documentation": "Test the functions by creating directories, reading, writing, and deleting files."
        },
        {
          "name": "logger",
          "type": "variable",
          "file_path": "actions/file_operations.py",
          "line_number": 6,
          "scope": "global",
          "purpose": "Used to log messages for each operation within the functions.",
          "documentation": "Configured logger instance used for logging information, warnings, and errors."
        }
      ],
      "framework_hints": [
        "asyncio for asynchronous operations"
      ],
      "last_modified": "2025-02-08T21:05:16.748118",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "asyncio",
          "os",
          "json",
          "csv",
          "typing",
          "logging"
        ],
        "imported_by": []
      }
    },
    "main.py": {
      "path": "main.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to initialize and run the Jiva AI Framework, which involves loading configurations, setting up the environment, initializing an agent, registering actions, and concurrently running a FastAPI application and the agent.",
      "exposures": [
        {
          "name": "load_config",
          "type": "exposure",
          "file_path": "main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "deep_update",
          "type": "exposure",
          "file_path": "main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "setup_environment",
          "type": "exposure",
          "file_path": "main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "print_welcome_message",
          "type": "exposure",
          "file_path": "main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "run_agent_and_api",
          "type": "exposure",
          "file_path": "main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "main",
          "type": "exposure",
          "file_path": "main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "os",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "uvicorn",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "api.main",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.agent",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "actions.action_registry",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "load_config",
          "type": "function",
          "file_path": "main.py",
          "line_number": 10,
          "scope": "main module",
          "purpose": "Load configuration from a JSON file or fallback to default values.",
          "documentation": "Load configuration from a file. Returns a dictionary with configuration settings."
        },
        {
          "name": "deep_update",
          "type": "function",
          "file_path": "main.py",
          "line_number": 54,
          "scope": "main module",
          "purpose": "Recursively update a dictionary with another dictionary.",
          "documentation": "Performs deep merging of two dictionaries."
        },
        {
          "name": "setup_environment",
          "type": "function",
          "file_path": "main.py",
          "line_number": 66,
          "scope": "main module",
          "purpose": "Set up necessary directories used by the application.",
          "documentation": "Creates 'data' and 'logs' directories if they don't exist."
        },
        {
          "name": "print_welcome_message",
          "type": "function",
          "file_path": "main.py",
          "line_number": 71,
          "scope": "main module",
          "purpose": "Print a welcome message to the console.",
          "documentation": "Displays an ASCII art and welcome message."
        },
        {
          "name": "run_agent_and_api",
          "type": "function",
          "file_path": "main.py",
          "line_number": 90,
          "scope": "main module",
          "purpose": "Run both the Jiva agent and the FastAPI server concurrently.",
          "documentation": "Uses asyncio to run the agent and server concurrently."
        },
        {
          "name": "main",
          "type": "function",
          "file_path": "main.py",
          "line_number": 112,
          "scope": "main module",
          "purpose": "Entry point for the application, initializing the framework and starting the main loop.",
          "documentation": "Sets up the environment, loads configuration, initializes the agent, and starts the agent and API server."
        },
        {
          "name": "logger",
          "type": "variable",
          "file_path": "main.py",
          "line_number": 8,
          "scope": "main module",
          "purpose": "Logger instance for the module.",
          "documentation": "Used for logging messages within the module."
        }
      ],
      "framework_hints": [
        "asyncio",
        "FastAPI",
        "Uvicorn"
      ],
      "last_modified": "2025-02-08T21:05:35.343734",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "json",
          "logging",
          "os",
          "asyncio",
          "uvicorn",
          "api.main",
          "typing",
          "core.agent",
          "actions.action_registry"
        ],
        "imported_by": []
      }
    },
    "LICENSE": {
      "path": "LICENSE",
      "language": "Unknown",
      "purpose": "The primary purpose of this text is to provide the terms and conditions of the MIT License for the use, distribution, and modification of the software.",
      "exposures": [
        {
          "name": "None (This is a license, not a code)",
          "type": "exposure",
          "file_path": "LICENSE",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "None (This is a license, not a code)",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "MIT License",
          "type": "license",
          "file_path": "LICENSE",
          "line_number": 0,
          "scope": "This is applicable to the software to which it is attached.",
          "purpose": "The MIT License is a permissive free software license.",
          "documentation": "This license permits reuse within proprietary software provided all copies of the licensed software include a copy of the license terms."
        }
      ],
      "framework_hints": [
        "None (This is a license, not a code)"
      ],
      "last_modified": "2025-02-08T21:06:01.090044",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "None (This is a license, not a code)"
        ],
        "imported_by": []
      }
    },
    "core/memory.py": {
      "path": "core/memory.py",
      "language": "Python",
      "purpose": "The code is designed to manage short-term and long-term memory for a system, storing data temporarily in short-term memory and transferring it to long-term storage when necessary. It uses semantic embeddings to manage and query memory with a connection to an external vector database (Qdrant).",
      "exposures": [
        {
          "name": "class DateTimeEncoder",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "class Memory",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "method add_to_short_term",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "method get_short_term_memory",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "method get_recent_short_term_memory",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "async method consolidate",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "async method query_long_term_memory",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "async method prepare_fine_tuning_dataset",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "method forget",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "method update_long_term_memory",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "method get_task_result",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "async method get_context_for_task",
          "type": "exposure",
          "file_path": "core/memory.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "datetime",
          "type": "external",
          "version": null,
          "used_by": [
            "core/agent.py",
            "core/time_experience.py",
            "api/main.py"
          ]
        },
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.llm_interface.LLMInterface",
          "type": "external",
          "version": null,
          "used_by": [
            "core/ethical_framework.py",
            "core/task_manager.py",
            "actions/action_registry.py",
            "core/action_manager.py"
          ]
        },
        {
          "name": "utils.qdrant_handler.QdrantHandler",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "DateTimeEncoder",
          "type": "class",
          "file_path": "core/memory.py",
          "line_number": 12,
          "scope": "global",
          "purpose": "Custom JSON encoder to handle datetime objects.",
          "documentation": "Overrides the default method to convert datetime objects into ISO format strings."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 19,
          "scope": "Memory",
          "purpose": "Initializes the Memory object with configurations and interfaces.",
          "documentation": "Sets up configuration values, short-term memory, logger, and sets up connection to Qdrant via QdrantHandler."
        },
        {
          "name": "add_to_short_term",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 33,
          "scope": "Memory",
          "purpose": "Adds a memory item into short-term memory.",
          "documentation": "Constructs a memory item with a timestamp and limited to a maximum size. Transfers oldest items to long-term storage when exceeding this size."
        },
        {
          "name": "_transfer_to_long_term",
          "type": "async method",
          "file_path": "core/memory.py",
          "line_number": 46,
          "scope": "Memory",
          "purpose": "Transfers a memory item from short-term to long-term storage using embeddings.",
          "documentation": "Serializes memory item to JSON, gets its embedding, checks vector size, and adds it to Qdrant."
        },
        {
          "name": "get_short_term_memory",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 66,
          "scope": "Memory",
          "purpose": "Retrieves all short-term memory items.",
          "documentation": "Returns the list of all items stored in short-term memory."
        },
        {
          "name": "get_recent_short_term_memory",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 71,
          "scope": "Memory",
          "purpose": "Retrieves the most recent 'n' items from short-term memory.",
          "documentation": "Fetches and returns up to 'n' most recent items from short-term memory."
        },
        {
          "name": "consolidate",
          "type": "async method",
          "file_path": "core/memory.py",
          "line_number": 76,
          "scope": "Memory",
          "purpose": "Transfers all short-term memory items to long-term storage.",
          "documentation": "Iterates over short-term memory items, transferring each to long-term storage and then clears short-term memory."
        },
        {
          "name": "query_long_term_memory",
          "type": "async method",
          "file_path": "core/memory.py",
          "line_number": 84,
          "scope": "Memory",
          "purpose": "Queries long-term memory based on a textual query.",
          "documentation": "Uses semantic embeddings to find and return most similar memory items from long-term storage in Qdrant."
        },
        {
          "name": "prepare_fine_tuning_dataset",
          "type": "async method",
          "file_path": "core/memory.py",
          "line_number": 95,
          "scope": "Memory",
          "purpose": "Prepares a dataset for model fine-tuning by collecting recent memories.",
          "documentation": "Combines short-term and long-term memories to create a dataset for fine-tuning purposes."
        },
        {
          "name": "forget",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 104,
          "scope": "Memory",
          "purpose": "Placeholder for deleting old or irrelevant memories from long-term storage.",
          "documentation": "Intended to remove memories based on some criteria which need to be defined for the specific application."
        },
        {
          "name": "update_long_term_memory",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 110,
          "scope": "Memory",
          "purpose": "Updates information in long-term memory.",
          "documentation": "Uses point IDs to find and update specific memories in the long-term storage."
        },
        {
          "name": "get_task_result",
          "type": "method",
          "file_path": "core/memory.py",
          "line_number": 122,
          "scope": "Memory",
          "purpose": "Finds the most recent result of a task given its description.",
          "documentation": "Searches short-term memory first and then long-term memory for tasks matching the description and returns the result."
        },
        {
          "name": "get_context_for_task",
          "type": "async method",
          "file_path": "core/memory.py",
          "line_number": 146,
          "scope": "Memory",
          "purpose": "Provides context for a given task description from both short-term and long-term memory.",
          "documentation": "Retrieves relevant short-term and long-term memory items to provide a contextualized view."
        }
      ],
      "framework_hints": [
        "asyncio",
        "unittest.mock"
      ],
      "last_modified": "2025-02-08T21:06:01.090350",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing",
          "datetime",
          "json",
          "logging",
          "core.llm_interface.LLMInterface",
          "utils.qdrant_handler.QdrantHandler"
        ],
        "imported_by": []
      }
    },
    "config.example.json": {
      "path": "config.example.json",
      "language": "Unknown",
      "purpose": "This configuration file is used for setting up an application involving memory storage, large language models (LLM), ethical guidelines, and operational parameters.",
      "exposures": [
        {
          "name": "memory",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "llm",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "llm-example-mistralai",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "ethical_framework",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "sleep_cycle",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "sensors",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "memory_consolidation_threshold",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "actions",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "agent_loop_delay",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "awake_duration",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "sleep_duration",
          "type": "exposure",
          "file_path": "config.example.json",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "qdrant",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "ollama",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "mistralai",
          "type": "external",
          "version": null,
          "used_by": [
            "llm_providers/mistral_ai_provider.py"
          ]
        }
      ],
      "elements": [
        {
          "name": "memory",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 2,
          "scope": "global",
          "purpose": "Configures memory storage settings including host, port, and specifications.",
          "documentation": "This JSON object contains configuration settings for memory management, including host and port information for the Qdrant vector database, collection name, and vector sizes used for memory representation."
        },
        {
          "name": "llm",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 10,
          "scope": "global",
          "purpose": "Configures connection parameters for the primary LLM provider.",
          "documentation": "Contains parameters for connecting to the primary large language model provider 'ollama', including API base URL, model name, number of retries, and timeout duration."
        },
        {
          "name": "llm-example-mistralai",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 17,
          "scope": "global",
          "purpose": "Configuration for an alternative model using MistralAI.",
          "documentation": "Provides an alternative configuration for the MistralAI large language model, specifying the API key, model, number of retries, and timeout duration."
        },
        {
          "name": "ethical_framework",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 25,
          "scope": "global",
          "purpose": "Specifies ethical guidelines for the application.",
          "documentation": "Contains ethical principles that guide the operation of the application, providing a framework for decision-making processes."
        },
        {
          "name": "sleep_cycle",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 32,
          "scope": "global",
          "purpose": "Defines sleep and awake durations for the application.",
          "documentation": "Controls whether the application cycles between awake and sleep states, and defines the duration of each state."
        },
        {
          "name": "sensors",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 38,
          "scope": "global",
          "purpose": "Configurations for interface sensors.",
          "documentation": "Currently configured for a chat interface sensor, defining the interaction prompt."
        },
        {
          "name": "memory_consolidation_threshold",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 42,
          "scope": "global",
          "purpose": "Set the threshold for memory consolidation.",
          "documentation": "Specifies the number of times data must be accessed before it is consolidated in memory."
        },
        {
          "name": "actions",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 43,
          "scope": "global",
          "purpose": "Reserves a place for future action definitions.",
          "documentation": "Currently an empty object; intended for defining actions the application can perform."
        },
        {
          "name": "agent_loop_delay",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 44,
          "scope": "global",
          "purpose": "Sets delay time for the agent's main loop.",
          "documentation": "Determines pause duration between cycles of the application\u2019s main operational loop."
        },
        {
          "name": "awake_duration",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 45,
          "scope": "global",
          "purpose": "Specifies how long the agent remains in the awake state.",
          "documentation": "Determine the duration in seconds for which the agent remains awake as part of its operation."
        },
        {
          "name": "sleep_duration",
          "type": "variable",
          "file_path": "config.example.json",
          "line_number": 46,
          "scope": "global",
          "purpose": "Sets the sleep state duration for the agent.",
          "documentation": "Specify the time duration in seconds for which the agent should remain in a sleep state."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:06:28.106230",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "qdrant",
          "ollama",
          "mistralai"
        ],
        "imported_by": []
      }
    },
    "llm_providers/anthropic_provider.py": {
      "path": "llm_providers/anthropic_provider.py",
      "language": "Python",
      "purpose": "This code defines a provider class for interacting with the Anthropic API to generate responses and obtain embeddings using Ollama.",
      "exposures": [
        {
          "name": "AnthropicProvider",
          "type": "exposure",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "generate",
          "type": "exposure",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_embedding",
          "type": "exposure",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "aiohttp",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "anthropic.AsyncAnthropic",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": ".base_provider.BaseLLMProvider",
          "type": "internal",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "AnthropicProvider",
          "type": "class",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 8,
          "scope": "global",
          "purpose": "A provider for generating responses and embeddings using Anthropic and Ollama APIs.",
          "documentation": "This class inherits from BaseLLMProvider and is used to interact with the Anthropic API for generating text responses and with the Ollama API for generating text embeddings."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 9,
          "scope": "AnthropicProvider",
          "purpose": "Initializes the AnthropicProvider with necessary configurations.",
          "documentation": "The constructor takes a configuration dictionary, initializes the API keys and model names for Anthropic and Ollama, and sets up a client for the Anthropic API."
        },
        {
          "name": "generate",
          "type": "method",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 19,
          "scope": "AnthropicProvider",
          "purpose": "Generates a response from the Anthropic model based on a given prompt.",
          "documentation": "An asynchronous method that sends a prompt to the Anthropic API and returns the generated response. It handles exceptions and raises a more informative error message if necessary."
        },
        {
          "name": "get_embedding",
          "type": "method",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 30,
          "scope": "AnthropicProvider",
          "purpose": "Gets an embedding for a given text using the Ollama API.",
          "documentation": "This asynchronous method sends a request to the Ollama API with the given text to obtain its embedding. It raises an exception in case of an error in the HTTP request."
        },
        {
          "name": "anthropic_api_key",
          "type": "variable",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 10,
          "scope": "AnthropicProvider",
          "purpose": "Store the API key for Anthropic API access.",
          "documentation": "A configuration parameter representing the API key needed to authenticate requests to the Anthropic API."
        },
        {
          "name": "anthropic_model",
          "type": "variable",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 11,
          "scope": "AnthropicProvider",
          "purpose": "Stores the model name used for generating responses from the Anthropic API.",
          "documentation": "A configuration parameter specifying which Anthropic model to use for generating responses. It defaults to 'claude-3-opus-20240229'."
        },
        {
          "name": "anthropic_client",
          "type": "variable",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 12,
          "scope": "AnthropicProvider",
          "purpose": "Client instance for interacting with the Anthropic API asynchronously.",
          "documentation": "An instance of the AsyncAnthropic class, used to make asynchronous API requests to the Anthropic service."
        },
        {
          "name": "ollama_api_base_url",
          "type": "variable",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 14,
          "scope": "AnthropicProvider",
          "purpose": "Stores the base URL for the Ollama API.",
          "documentation": "A configuration parameter representing the URL endpoint for the Ollama API, defaulting to 'http://localhost:11434/api'."
        },
        {
          "name": "ollama_embedding_model",
          "type": "variable",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 15,
          "scope": "AnthropicProvider",
          "purpose": "Stores the model name used for embeddings in the Ollama API.",
          "documentation": "A configuration parameter specifying which model to use for generating embeddings. It defaults to 'nomic-embed-text'."
        },
        {
          "name": "ollama_timeout",
          "type": "variable",
          "file_path": "llm_providers/anthropic_provider.py",
          "line_number": 16,
          "scope": "AnthropicProvider",
          "purpose": "Timeout duration for Ollama API requests.",
          "documentation": "A configuration parameter that sets the time in seconds to wait for a response from the Ollama API before timing out."
        }
      ],
      "framework_hints": [
        "asyncio",
        "aiohttp"
      ],
      "last_modified": "2025-02-08T21:06:56.343329",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing",
          "json",
          "aiohttp",
          "anthropic.AsyncAnthropic",
          ".base_provider.BaseLLMProvider"
        ],
        "imported_by": []
      }
    },
    "core/llm_interface.py": {
      "path": "core/llm_interface.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to provide an interface for interacting with various language models (LLMs), handling generation, JSON parsing, and processing tasks.",
      "exposures": [
        {
          "name": "LLMInterface",
          "type": "exposure",
          "file_path": "core/llm_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "generate",
          "type": "exposure",
          "file_path": "core/llm_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "parse_json",
          "type": "exposure",
          "file_path": "core/llm_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "process",
          "type": "exposure",
          "file_path": "core/llm_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_embedding",
          "type": "exposure",
          "file_path": "core/llm_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "fine_tune",
          "type": "exposure",
          "file_path": "core/llm_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "re",
          "type": "external",
          "version": null,
          "used_by": [
            "core/task_manager.py"
          ]
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "tenacity",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "llm_providers.base_provider",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "llm_providers.ollama_provider",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "llm_providers.openai_provider",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "llm_providers.anthropic_provider",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "llm_providers.mistral_ai_provider",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "JSONParseError",
          "type": "class",
          "file_path": "core/llm_interface.py",
          "line_number": 15,
          "scope": null,
          "purpose": "Custom exception class for JSON parsing errors.",
          "documentation": "A simple exception class for when JSON parsing fails."
        },
        {
          "name": "LLMInterface",
          "type": "class",
          "file_path": "core/llm_interface.py",
          "line_number": 18,
          "scope": null,
          "purpose": "Provides an interface for interacting with different LLM providers.",
          "documentation": "A class that initializes with a configuration and allows operations like generating content, parsing JSON, processing input, getting embeddings, and fine-tuning models."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 19,
          "scope": "LLMInterface",
          "purpose": "Initialize LLMInterface with configuration and select the provider.",
          "documentation": "Initializes the interface with the given configuration dictionary, sets up the logger, and selects the appropriate provider based on the configuration."
        },
        {
          "name": "_get_provider",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 25,
          "scope": "LLMInterface",
          "purpose": "Selects the appropriate LLM provider based on configuration.",
          "documentation": "Determines which provider to use by checking the 'provider' key in the configuration, defaulting to 'ollama'. Raises a ValueError if the provider is not supported."
        },
        {
          "name": "generate",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 43,
          "scope": "LLMInterface",
          "purpose": "Generate a response from the LLM.",
          "documentation": "Asynchronously generates a response based on a given prompt. Uses retry logic to handle failures."
        },
        {
          "name": "parse_json",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 56,
          "scope": "LLMInterface",
          "purpose": "Parses a JSON object from an LLM response.",
          "documentation": "Attempts to extract and parse JSON from responses. If parsing fails, it returns an error dictionary."
        },
        {
          "name": "_attempt_parse",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 80,
          "scope": "LLMInterface",
          "purpose": "Try to parse a string as JSON.",
          "documentation": "Attempts to decode a JSON string and return the JSON object, returns None if parsing fails."
        },
        {
          "name": "_extract_json_from_response",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 93,
          "scope": "LLMInterface",
          "purpose": "Extracts JSON string from potential formats in the response.",
          "documentation": "Searches for JSON blocks in the response, either enclosed in markdown code blocks or JSON-like structures, returning the first valid find."
        },
        {
          "name": "_fix_json_syntax",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 114,
          "scope": "LLMInterface",
          "purpose": "Fix common JSON syntax errors.",
          "documentation": "Attempts to repair JSON syntax issues such as missing commas, unclosed quotes, and trailing commas."
        },
        {
          "name": "_construct_json_from_text",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 131,
          "scope": "LLMInterface",
          "purpose": "Construct a JSON-like structure from free text.",
          "documentation": "Tries to identify and pair keys and values in text to build a JSON-like object when direct JSON parsing fails."
        },
        {
          "name": "process",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 162,
          "scope": "LLMInterface",
          "purpose": "Processes input data and returns structured information.",
          "documentation": "Generates a structured JSON response by analyzing input data, breaking it into action items and key categories."
        },
        {
          "name": "get_embedding",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 182,
          "scope": "LLMInterface",
          "purpose": "Retrieve embeddings for a given text.",
          "documentation": "Asynchronously gets an embedding vector for the provided text from the LLM provider."
        },
        {
          "name": "fine_tune",
          "type": "method",
          "file_path": "core/llm_interface.py",
          "line_number": 191,
          "scope": "LLMInterface",
          "purpose": "Initiates model fine-tuning.",
          "documentation": "Placeholder function for fine-tuning logic, warns that it's not implemented for the current provider."
        }
      ],
      "framework_hints": [
        "tenacity"
      ],
      "last_modified": "2025-02-08T21:07:23.190780",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "json",
          "logging",
          "re",
          "typing",
          "tenacity",
          "llm_providers.base_provider",
          "llm_providers.ollama_provider",
          "llm_providers.openai_provider",
          "llm_providers.anthropic_provider",
          "llm_providers.mistral_ai_provider"
        ],
        "imported_by": []
      }
    },
    "core/ethical_framework.py": {
      "path": "core/ethical_framework.py",
      "language": "Python",
      "purpose": "This code implements an ethical framework for evaluating tasks and actions based on predefined ethical principles, utilizing a language model interface to perform such evaluations.",
      "exposures": [
        {
          "name": "EthicalFramework",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "set_enabled",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "evaluate_task",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "evaluate_action",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_ethical_explanation",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "update_ethical_principles",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_ethical_dilemma_resolution",
          "type": "exposure",
          "file_path": "core/ethical_framework.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing.List",
          "type": "external",
          "version": null,
          "used_by": [
            "utils/qdrant_handler.py",
            "core/task_manager.py"
          ]
        },
        {
          "name": "typing.Dict",
          "type": "external",
          "version": null,
          "used_by": [
            "utils/qdrant_handler.py",
            "core/task_manager.py",
            "actions/action_registry.py"
          ]
        },
        {
          "name": "typing.Any",
          "type": "external",
          "version": null,
          "used_by": [
            "utils/qdrant_handler.py",
            "core/task_manager.py",
            "actions/action_registry.py"
          ]
        },
        {
          "name": "typing.Union",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.llm_interface.LLMInterface",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "EthicalFramework",
          "type": "class",
          "file_path": "core/ethical_framework.py",
          "line_number": 8,
          "scope": "global",
          "purpose": "Manages ethical evaluations and decision-making logic based on ethical principles.",
          "documentation": "The class encapsulates functionalities to enable/disable the ethical framework, evaluate tasks or actions for ethical considerations, and update ethical principles."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/ethical_framework.py",
          "line_number": 9,
          "scope": "instance",
          "purpose": "Initializes the EthicalFramework instance with a language model interface and configuration.",
          "documentation": "Constructor that sets initial values for the framework, including the language model interface, logger, ethical principles, and enabled status."
        },
        {
          "name": "set_enabled",
          "type": "method",
          "file_path": "core/ethical_framework.py",
          "line_number": 19,
          "scope": "instance",
          "purpose": "Enables or disables the ethical framework.",
          "documentation": "Updates the 'enabled' status of the framework and logs the action."
        },
        {
          "name": "evaluate_task",
          "type": "method",
          "file_path": "core/ethical_framework.py",
          "line_number": 24,
          "scope": "instance",
          "purpose": "Evaluates a task to determine if it is ethical based on the defined principles.",
          "documentation": "Checks if the framework is enabled, then evaluates the task using a basic rule set or generates a prompt for the LLMInterface to assess."
        },
        {
          "name": "evaluate_action",
          "type": "async method",
          "file_path": "core/ethical_framework.py",
          "line_number": 61,
          "scope": "instance",
          "purpose": "Asynchronously evaluates an action and its parameters for ethical considerations.",
          "documentation": "Evaluates actions by creating a prompt for the LLMInterface, which in turn gives an ethical assessment based on the provided details."
        },
        {
          "name": "get_ethical_explanation",
          "type": "async method",
          "file_path": "core/ethical_framework.py",
          "line_number": 84,
          "scope": "instance",
          "purpose": "Retrieves a detailed ethical explanation for a given task or action.",
          "documentation": "Asynchronously requests a generated explanation from the LLMInterface detailing how a task or action aligns with or violates ethical principles."
        },
        {
          "name": "update_ethical_principles",
          "type": "method",
          "file_path": "core/ethical_framework.py",
          "line_number": 98,
          "scope": "instance",
          "purpose": "Updates the list of ethical principles used by the framework.",
          "documentation": "Allows modification of the framework's ethical principles, supporting adaptability over time."
        },
        {
          "name": "get_ethical_dilemma_resolution",
          "type": "async method",
          "file_path": "core/ethical_framework.py",
          "line_number": 104,
          "scope": "instance",
          "purpose": "Asynchronously resolves ethical dilemmas based on the framework's principles.",
          "documentation": "Analyzes dilemmas by leveraging the LLMInterface to generate a reasoned resolution to ethical challenges."
        },
        {
          "name": "MockLLMInterface",
          "type": "class",
          "file_path": "core/ethical_framework.py",
          "line_number": 128,
          "scope": "local",
          "purpose": "Simulates a language model interface for testing purposes.",
          "documentation": "Provides a simple mock implementation for generating responses and parsing JSON, facilitating testing of the EthicalFramework."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:07:50.658522",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing.List",
          "typing.Dict",
          "typing.Any",
          "typing.Union",
          "logging",
          "core.llm_interface.LLMInterface"
        ],
        "imported_by": []
      }
    },
    "core/agent.py": {
      "path": "core/agent.py",
      "language": "Python",
      "purpose": "The code implements a sophisticated autonomous agent system named 'Jiva' designed to interact with its environment through sensory inputs, perform tasks, manage its own memory, and follow ethical guidelines. It utilizes a long-lived loop to continuously process inputs, set and execute tasks, handle errors, and manage its sleep and memory consolidation cycles.",
      "exposures": [
        {
          "name": "Agent",
          "type": "exposure",
          "file_path": "core/agent.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "DateTimeEncoder",
          "type": "exposure",
          "file_path": "core/agent.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "datetime",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "os",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "RotatingFileHandler",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "Memory",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "TimeExperience",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "TaskManager",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "EthicalFramework",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "LLMInterface",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "SensorManager",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "ActionManager",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "DateTimeEncoder",
          "type": "class",
          "file_path": "core/agent.py",
          "line_number": 19,
          "scope": "core/agent.py",
          "purpose": "Custom JSON encoder to handle datetime and timedelta objects.",
          "documentation": "Extends the functionality of json.JSONEncoder to convert datetime and timedelta objects to ISO format for JSON serialization."
        },
        {
          "name": "Agent",
          "type": "class",
          "file_path": "core/agent.py",
          "line_number": 25,
          "scope": "core/agent.py",
          "purpose": "Defines the behavior and functionalities of the Jiva agent, including initialization and operational loop management.",
          "documentation": "Main class for the agent. It manages configurations, sensors, memory, tasks, and more. Handles lifecycle operations including a main loop for operation, processing input, task execution, and memory management."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 26,
          "scope": "Agent",
          "purpose": "Initializes an instance of the Agent class with the provided configuration.",
          "documentation": "Sets up logging, initializes components and configurations such as LLM interface, memory, managers for tasks, sensors, and actions. Also configures the agent's sleep cycle settings, and prepares variables for runtime."
        },
        {
          "name": "run",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 53,
          "scope": "Agent",
          "purpose": "Main execution loop for the agent.",
          "documentation": "An async method running indefinitely, it checks for and processes sensory inputs, executes tasks, manages sleep cycles, and handles memory consolidation, with error handling mechanisms."
        },
        {
          "name": "create_time_memory",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 131,
          "scope": "Agent",
          "purpose": "Creates a time-based memory entry.",
          "documentation": "Adds a new time-based memory into the agent's short-term memory to reflect the current timestamp and description of this time experience."
        },
        {
          "name": "should_consolidate_memories",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 139,
          "scope": "Agent",
          "purpose": "Determines if memory consolidation should be executed.",
          "documentation": "Checks if the threshold for memory consolidation has been reached and if there are no pending tasks, indicating readiness for memory consolidation."
        },
        {
          "name": "process_input",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 143,
          "scope": "Agent",
          "purpose": "Processes sensory input data.",
          "documentation": "Asynchronously processes input data, interacts with the LLM interface to process content, updates memory, sets new goals if identified, and possibly generates new tasks."
        },
        {
          "name": "is_goal_setting",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 173,
          "scope": "Agent",
          "purpose": "Determines if processed input is establishing a new goal.",
          "documentation": "Interacts with the LLM to analyze specific input and decide whether it sets a new goal for the agent based on the current context."
        },
        {
          "name": "set_new_goal",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 182,
          "scope": "Agent",
          "purpose": "Sets a new goal for the agent based on the processed input.",
          "documentation": "Uses LLM to generate a concise goal statement from input, updates current goal, and creates tasks relating to this new goal."
        },
        {
          "name": "get_context",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 198,
          "scope": "Agent",
          "purpose": "Retrieves the current context of the agent.",
          "documentation": "Gathers the current state of the agent including recent memories, current time, and current goal, formatted in a dictionary for contextual operations."
        },
        {
          "name": "execute_next_task",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 209,
          "scope": "Agent",
          "purpose": "Executes the next pending task from the queue.",
          "documentation": "Asynchronously gets the next task from the task manager, executes it, and processes the result or handles errors if encountered."
        },
        {
          "name": "handle_task_error",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 224,
          "scope": "Agent",
          "purpose": "Handles errors encountered during task execution.",
          "documentation": "Uses the LLM interface to generate solutions or alternative approaches to resolve task errors and may introduce new tasks based on these solutions."
        },
        {
          "name": "parse_action_plan",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 241,
          "scope": "Agent",
          "purpose": "Parses an action plan into actionable elements.",
          "documentation": "Utilizes the LLM to convert a high-level action plan into an action name and corresponding parameters, formatted as a JSON object."
        },
        {
          "name": "process_task_result",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 248,
          "scope": "Agent",
          "purpose": "Processes the results of a completed task.",
          "documentation": "Records task results into memory, marks task completion, and evaluates the need for generating follow-up tasks based on results."
        },
        {
          "name": "check_and_handle_sleep",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 273,
          "scope": "Agent",
          "purpose": "Manages the agent's sleep and wake cycles.",
          "documentation": "Checks the conditions for sleep or wake states based on configurations and current time metrics, adjusting the agent state accordingly."
        },
        {
          "name": "sleep",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 299,
          "scope": "Agent",
          "purpose": "Puts the agent into a sleep state.",
          "documentation": "Switches the agent to a non-active state, triggering memory consolidation and preparing datasets for potential fine-tuning of models."
        },
        {
          "name": "wake_up",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 314,
          "scope": "Agent",
          "purpose": "Wakes the agent from its sleep state.",
          "documentation": "Sets the agent to active, updating its experience with current time settings."
        },
        {
          "name": "setup_logging",
          "type": "method",
          "file_path": "core/agent.py",
          "line_number": 317,
          "scope": "Agent",
          "purpose": "Configures logging mechanisms for the agent.",
          "documentation": "Initializes logging to both console and rotating files to keep detailed operational logs, supporting debugging and monitoring."
        }
      ],
      "framework_hints": [
        "asyncio for asynchronous programming",
        "logging for operational logging",
        "json for serialization/deserialization of data",
        "os for file operations"
      ],
      "last_modified": "2025-02-08T21:07:50.658660",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "asyncio",
          "datetime",
          "os",
          "json",
          "logging",
          "RotatingFileHandler",
          "Memory",
          "TimeExperience",
          "TaskManager",
          "EthicalFramework",
          "LLMInterface",
          "SensorManager",
          "ActionManager"
        ],
        "imported_by": []
      }
    },
    "llm_providers/ollama_provider.py": {
      "path": "llm_providers/ollama_provider.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to define a provider class, 'OllamaProvider', for interacting with a language model API. It provides methods to generate text based on a prompt and to retrieve text embeddings.",
      "exposures": [
        {
          "name": "OllamaProvider",
          "type": "exposure",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "aiohttp",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "base_provider",
          "type": "external",
          "version": null,
          "used_by": [
            "llm_providers/mistral_ai_provider.py"
          ]
        }
      ],
      "elements": [
        {
          "name": "OllamaProvider",
          "type": "class",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 6,
          "scope": "global",
          "purpose": "Represents a provider for language model operations, such as text generation and embedding retrieval.",
          "documentation": "This class is a concrete implementation of the BaseLLMProvider. It interacts with a language model API offering functionalities to generate text and get text embeddings."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 7,
          "scope": "OllamaProvider",
          "purpose": "Initializes an instance of OllamaProvider with configuration settings.",
          "documentation": "Constructor to set up the base URL, model type, maximum retries, and timeout for API requests."
        },
        {
          "name": "generate",
          "type": "method",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 14,
          "scope": "OllamaProvider",
          "purpose": "Generates text based on a provided prompt using a specific language model.",
          "documentation": "This asynchronous method sends a POST request to the language model API's generate endpoint with the model and prompt in JSON format and returns the generated response as a string."
        },
        {
          "name": "get_embedding",
          "type": "method",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 24,
          "scope": "OllamaProvider",
          "purpose": "Retrieves embeddings for a given text from the language model.",
          "documentation": "This asynchronous method sends a POST request to the language model API's embeddings endpoint with the model and text in JSON format, then returns the response embedding as a list of floats."
        },
        {
          "name": "api_base_url",
          "type": "variable",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 8,
          "scope": "OllamaProvider",
          "purpose": "Stores the base URL for the API requests.",
          "documentation": "This instance variable holds the default or configured base URL for API communication. Default is 'http://localhost:11434/api'."
        },
        {
          "name": "model",
          "type": "variable",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 9,
          "scope": "OllamaProvider",
          "purpose": "Specifies the language model to be used by the provider.",
          "documentation": "This instance variable stores the model identifier used in API requests. Default is 'gemma'."
        },
        {
          "name": "max_retries",
          "type": "variable",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 10,
          "scope": "OllamaProvider",
          "purpose": "Defines the maximum number of retries for API requests.",
          "documentation": "This instance variable sets the number of retry attempts in case of API request failures. Default is 3."
        },
        {
          "name": "timeout",
          "type": "variable",
          "file_path": "llm_providers/ollama_provider.py",
          "line_number": 11,
          "scope": "OllamaProvider",
          "purpose": "Sets the timeout for API requests.",
          "documentation": "This instance variable defines the maximum time to wait for an API response. Default is 60 seconds."
        }
      ],
      "framework_hints": [
        "aiohttp",
        "asyncio"
      ],
      "last_modified": "2025-02-08T21:09:01.196012",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "json",
          "aiohttp",
          "typing",
          "base_provider"
        ],
        "imported_by": []
      }
    },
    "logs/logs-backup/jiva.log.2": {
      "path": "logs/logs-backup/jiva.log.2",
      "language": "Unknown",
      "purpose": "File in logs-backup module",
      "exposures": [],
      "dependencies": [
        {
          "name": "java",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:09:01.196690",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "java"
        ],
        "imported_by": []
      }
    },
    ".fluen/cache/state.json": {
      "path": ".fluen/cache/state.json",
      "language": "Unknown",
      "purpose": "Represents a data structure possibly for tracking the progress of a file processing operation.",
      "exposures": [],
      "dependencies": [],
      "elements": [
        {
          "name": "last_commit",
          "type": "variable",
          "file_path": ".fluen/cache/state.json",
          "line_number": 1,
          "scope": "global",
          "purpose": "Stores the identifier of the last commit processed or referenced.",
          "documentation": "This field may be used to track integration with version control, likely to know until which point the data processing has been consistent with."
        },
        {
          "name": "last_run_timestamp",
          "type": "variable",
          "file_path": ".fluen/cache/state.json",
          "line_number": 2,
          "scope": "global",
          "purpose": "Indicates the timestamp of the last execution of the associated process.",
          "documentation": "Helps in knowing when the last full or partial execution occurred, useful in logging or synchronization operations."
        },
        {
          "name": "files_processed",
          "type": "variable",
          "file_path": ".fluen/cache/state.json",
          "line_number": 3,
          "scope": "global",
          "purpose": "Keeps count of how many files have been processed.",
          "documentation": "This numeric field tracks progress by counting files already handled, assisting in monitoring and reporting."
        },
        {
          "name": "total_files",
          "type": "variable",
          "file_path": ".fluen/cache/state.json",
          "line_number": 4,
          "scope": "global",
          "purpose": "Denotes the total number of files intended to be processed.",
          "documentation": "Useful for checking progress against the work completed by comparing it with 'files_processed'."
        },
        {
          "name": "manifest_path",
          "type": "variable",
          "file_path": ".fluen/cache/state.json",
          "line_number": 5,
          "scope": "global",
          "purpose": "Holds the file path for a manifest, if applicable.",
          "documentation": "May point to a manifest or configuration file which details file information, dependencies, or settings for the operation."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:09:12.527492",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [],
        "imported_by": []
      }
    },
    "models/embeddings.py": {
      "path": "models/embeddings.py",
      "language": "Python",
      "purpose": "The code provides functionality to get an embedding vector for a given text using a specific model hosted on a local API server.",
      "exposures": [
        {
          "name": "get_embedding",
          "type": "exposure",
          "file_path": "models/embeddings.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "json",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "requests",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "OLLAMA_API_BASE_URL",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 6,
          "scope": "module-level",
          "purpose": "Stores the base URL of the local API server.",
          "documentation": "A string constant that specifies the base URL where the embedding API is hosted."
        },
        {
          "name": "EMBED_MODEL",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 7,
          "scope": "module-level",
          "purpose": "Defines the model to be used for text embedding.",
          "documentation": "A string constant that specifies the name of the embedding model to use."
        },
        {
          "name": "get_embedding",
          "type": "function",
          "file_path": "models/embeddings.py",
          "line_number": 9,
          "scope": "public",
          "purpose": "Fetches the embedding vector for a given text using a remote API.",
          "documentation": "The function sends a POST request to the embedding API and retrieves the embedding vector for the specified text."
        },
        {
          "name": "url",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 17,
          "scope": "local (within get_embedding)",
          "purpose": "Constructs the endpoint URL for the embedding API.",
          "documentation": "A local variable within the get_embedding function, concatenating the base URL and endpoint."
        },
        {
          "name": "payload",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 19,
          "scope": "local (within get_embedding)",
          "purpose": "Holds the JSON payload to be sent in the POST request.",
          "documentation": "A JSON-formatted string containing the model name and text prompt for the API request."
        },
        {
          "name": "headers",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 24,
          "scope": "local (within get_embedding)",
          "purpose": "Specifies the request headers for the POST request.",
          "documentation": "A dictionary specifying the Content-Type as application/json."
        },
        {
          "name": "response",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 27,
          "scope": "local (within get_embedding)",
          "purpose": "Stores the HTTP response returned by the API request.",
          "documentation": "The response object returned by the requests.post call, containing the status and content of the HTTP response."
        },
        {
          "name": "result",
          "type": "variable",
          "file_path": "models/embeddings.py",
          "line_number": 30,
          "scope": "local (within get_embedding)",
          "purpose": "Processes the JSON response from the API to extract the embedding.",
          "documentation": "A dictionary parsed from the JSON response containing the embedding vector."
        },
        {
          "name": "__main__",
          "type": "scope",
          "file_path": "models/embeddings.py",
          "line_number": 32,
          "scope": "file",
          "purpose": "Allows the script to be run directly for testing.",
          "documentation": "The block of code under the if __name__ == \"__main__\" clause serves for basic testing by embedding a sample text."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:09:28.738074",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "json",
          "requests"
        ],
        "imported_by": []
      }
    },
    "utils/qdrant_handler.py": {
      "path": "utils/qdrant_handler.py",
      "language": "Python",
      "purpose": "The code provides an interface to interact with a Qdrant database, handling operations such as creating collections, adding points, searching, updating, and deleting points in a vector database.",
      "exposures": [
        {
          "name": "QdrantHandler.__init__",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "QdrantHandler.add_point",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "QdrantHandler.search",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "QdrantHandler.update_point",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "QdrantHandler.delete_point",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "QdrantHandler.get_point",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "QdrantHandler.delete_collection",
          "type": "exposure",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing.List",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Dict",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Any",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.AsyncQdrantClient",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.http.models.Distance",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.http.models.VectorParams",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.http.models.PointStruct",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.http.models.UpdateStatus",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.http.exceptions.ResponseHandlingException",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant_client.http.exceptions.UnexpectedResponse",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "uuid",
          "type": "external",
          "version": null,
          "used_by": [
            "core/task_manager.py"
          ]
        }
      ],
      "elements": [
        {
          "name": "QdrantHandler",
          "type": "class",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 9,
          "scope": "module",
          "purpose": "Main handler class for Qdrant operations.",
          "documentation": "This class encapsulates methods for handling collection and point operations with a Qdrant vector database. It includes collection creation, point insertion, search, update, and deletion functionalities."
        },
        {
          "name": "QdrantHandler.__init__",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 10,
          "scope": "QdrantHandler",
          "purpose": "Initializes the QdrantHandler instance.",
          "documentation": "Sets up the Qdrant client, validates collection existence, and initializes logging. Takes host, port, collection_name, and vector_size as parameters."
        },
        {
          "name": "QdrantHandler._ensure_collection_exists",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 16,
          "scope": "QdrantHandler",
          "purpose": "Ensures that the specified collection exists in the database.",
          "documentation": "Checks if the collection exists and creates it if not. Handles exceptions and logs errors."
        },
        {
          "name": "QdrantHandler._create_collection",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 29,
          "scope": "QdrantHandler",
          "purpose": "Creates a new collection with the specified configuration.",
          "documentation": "Utilizes the Qdrant client to create a collection, specifying vector size and distance metric. Logs the creation status."
        },
        {
          "name": "QdrantHandler.add_point",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 38,
          "scope": "QdrantHandler",
          "purpose": "Adds a point to the Qdrant collection asynchronously.",
          "documentation": "Inserts a point described by a vector and payload to the collection using a unique ID. Returns the point ID or None if an error occurs."
        },
        {
          "name": "QdrantHandler.search",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 57,
          "scope": "QdrantHandler",
          "purpose": "Searches for similar points in the collection based on a query vector.",
          "documentation": "Executes a search query against the collection with the option to limit results, returning a list of matching points with their IDs, payloads, and scores."
        },
        {
          "name": "QdrantHandler.update_point",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 70,
          "scope": "QdrantHandler",
          "purpose": "Updates an existing point's vector and/or payload.",
          "documentation": "Replaces an existing point's data in the collection using its ID. Returns the update status."
        },
        {
          "name": "QdrantHandler.delete_point",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 75,
          "scope": "QdrantHandler",
          "purpose": "Deletes a specific point from the collection.",
          "documentation": "Removes the point with the specified ID from the collection. Returns the update status."
        },
        {
          "name": "QdrantHandler.get_point",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 81,
          "scope": "QdrantHandler",
          "purpose": "Retrieves a specific point from the collection by ID.",
          "documentation": "Fetches and returns the point's data, including the ID and payload, if it exists in the collection. Returns None if not found."
        },
        {
          "name": "QdrantHandler.delete_collection",
          "type": "method",
          "file_path": "utils/qdrant_handler.py",
          "line_number": 89,
          "scope": "QdrantHandler",
          "purpose": "Deletes the entire collection from the Qdrant database.",
          "documentation": "Removes the specified collection, logging the event. Handles errors and logs them."
        }
      ],
      "framework_hints": [
        "async_await",
        "logging"
      ],
      "last_modified": "2025-02-08T21:09:48.580619",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing.List",
          "typing.Dict",
          "typing.Any",
          "qdrant_client.AsyncQdrantClient",
          "qdrant_client.http.models.Distance",
          "qdrant_client.http.models.VectorParams",
          "qdrant_client.http.models.PointStruct",
          "qdrant_client.http.models.UpdateStatus",
          "qdrant_client.http.exceptions.ResponseHandlingException",
          "qdrant_client.http.exceptions.UnexpectedResponse",
          "logging",
          "uuid"
        ],
        "imported_by": []
      }
    },
    "logs/logs-backup/jiva.log.1": {
      "path": "logs/logs-backup/jiva.log.1",
      "language": "Unknown",
      "purpose": "File in logs-backup module",
      "exposures": [],
      "dependencies": [],
      "elements": [],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:10:51.451154",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [],
        "imported_by": []
      }
    },
    "llm_providers/base_provider.py": {
      "path": "llm_providers/base_provider.py",
      "language": "Python",
      "purpose": "This code defines an abstract base class for language model providers, specifying required methods for generating text and obtaining text embeddings.",
      "exposures": [
        {
          "name": "BaseLLMProvider",
          "type": "exposure",
          "file_path": "llm_providers/base_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "abc",
          "type": "external",
          "version": null,
          "used_by": [
            "sensors/sensor_base.py"
          ]
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "BaseLLMProvider",
          "type": "class",
          "file_path": "llm_providers/base_provider.py",
          "line_number": 5,
          "scope": "global",
          "purpose": "Defines a contract for large language model (LLM) providers.",
          "documentation": "BaseLLMProvider is an abstract base class for LLM provider implementations. It requires subclasses to implement two methods: generate and get_embedding."
        },
        {
          "name": "generate",
          "type": "method",
          "file_path": "llm_providers/base_provider.py",
          "line_number": 7,
          "scope": "class:BaseLLMProvider",
          "purpose": "Abstract method for generating text from a given prompt.",
          "documentation": "Subclasses must implement the generate method, which accepts a string prompt and returns a generated string asynchronously."
        },
        {
          "name": "get_embedding",
          "type": "method",
          "file_path": "llm_providers/base_provider.py",
          "line_number": 11,
          "scope": "class:BaseLLMProvider",
          "purpose": "Abstract method for obtaining text embeddings.",
          "documentation": "Subclasses must implement the get_embedding method, which accepts a string and returns a list of floats representing the text embedding asynchronously."
        }
      ],
      "framework_hints": [
        "abstractmethod",
        "asyncio"
      ],
      "last_modified": "2025-02-08T21:10:58.117127",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "abc",
          "typing"
        ],
        "imported_by": []
      }
    },
    "core/task_manager.py": {
      "path": "core/task_manager.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to manage tasks in a system that integrates with various core components like LLM, ethical evaluation, action management, and memory. The tasks are structured with priorities, dependencies, and are executed sequentially.",
      "exposures": [
        {
          "name": "Task",
          "type": "exposure",
          "file_path": "core/task_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TaskManager",
          "type": "exposure",
          "file_path": "core/task_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "parse_int_or_default",
          "type": "exposure",
          "file_path": "core/task_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "re",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.List",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Dict",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Any",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Optional",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "queue.PriorityQueue",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "datetime.datetime",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "uuid",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.llm_interface.LLMInterface",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.ethical_framework.EthicalFramework",
          "type": "external",
          "version": null,
          "used_by": [
            "core/action_manager.py"
          ]
        },
        {
          "name": "core.action_manager.ActionManager",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.memory.Memory",
          "type": "external",
          "version": null,
          "used_by": [
            "actions/action_registry.py",
            "core/action_manager.py"
          ]
        }
      ],
      "elements": [
        {
          "name": "parse_int_or_default",
          "type": "function",
          "file_path": "core/task_manager.py",
          "line_number": 12,
          "scope": "global",
          "purpose": "Parses a string as an integer, or returns a default value if parsing fails.",
          "documentation": "A utility function to safely convert a value to an integer, providing a fallback to a default integer value."
        },
        {
          "name": "Task",
          "type": "class",
          "file_path": "core/task_manager.py",
          "line_number": 20,
          "scope": "global",
          "purpose": "Represents an individual task with its details and methods for comparison.",
          "documentation": "Class for encapsulating the properties and behavior of a task including initialization, comparison, and representation."
        },
        {
          "name": "__init__ in Task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 21,
          "scope": "Task",
          "purpose": "Initializes a Task instance with its attributes.",
          "documentation": "Constructor for Task class to initialize all parameters of a task including description, action, priority, etc."
        },
        {
          "name": "__lt__ in Task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 37,
          "scope": "Task",
          "purpose": "Defines the less-than comparison based on priority and creation time.",
          "documentation": "A comparison magic method to prioritize tasks by checking priority and creation time."
        },
        {
          "name": "__eq__ in Task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 42,
          "scope": "Task",
          "purpose": "Checks equality between two Task objects based on their ID.",
          "documentation": "Compares Task instances for equality using their unique IDs."
        },
        {
          "name": "__repr__ in Task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 46,
          "scope": "Task",
          "purpose": "Provides a string representation of the Task for debugging.",
          "documentation": "Represents a Task object as a string including its ID, description, priority, and status."
        },
        {
          "name": "TaskManager",
          "type": "class",
          "file_path": "core/task_manager.py",
          "line_number": 49,
          "scope": "global",
          "purpose": "Manages tasks including creation, execution, and status tracking.",
          "documentation": "A class for task handling operations, using a priority queue and interfacing with components like LLM and memory."
        },
        {
          "name": "__init__ in TaskManager",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 50,
          "scope": "TaskManager",
          "purpose": "Initializes the TaskManager with its dependencies.",
          "documentation": "Constructor for TaskManager to initialize necessary components and logging functionalities."
        },
        {
          "name": "get_relevant_actions",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 60,
          "scope": "TaskManager",
          "purpose": "Gathers relevant actions for a given goal and context.",
          "documentation": "Asynchronously fetches and returns a list of action names relevant to the input goal and context."
        },
        {
          "name": "generate_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 83,
          "scope": "TaskManager",
          "purpose": "Generates tasks based on a goal and context.",
          "documentation": "Asynchronously creates a set of tasks using an LLM prompt and parses the response to generate tasks."
        },
        {
          "name": "add_raw_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 143,
          "scope": "TaskManager",
          "purpose": "Adds tasks from dictionaries to the task management system.",
          "documentation": "Processes raw task dictionaries and enqueues them after wrapping in Task instances."
        },
        {
          "name": "requeue_pending_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 165,
          "scope": "TaskManager",
          "purpose": "Requeues tasks that are pending but not currently in the queue.",
          "documentation": "Identifies and places pending tasks back into the task queue to ensure they are processed."
        },
        {
          "name": "add_task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 182,
          "scope": "TaskManager",
          "purpose": "Adds a new task after evaluating its ethical implications.",
          "documentation": "Creates and adds a new task to the queue and records it if ethical evaluation passes."
        },
        {
          "name": "get_next_task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 199,
          "scope": "TaskManager",
          "purpose": "Retrieves the next task from the queue.",
          "documentation": "Fetches and returns the highest priority task from the queue, if available."
        },
        {
          "name": "complete_task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 204,
          "scope": "TaskManager",
          "purpose": "Marks a task as completed and stores its result.",
          "documentation": "Updates task status to completed and records its result; ensures it is removed from the queue."
        },
        {
          "name": "get_task_status",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 238,
          "scope": "TaskManager",
          "purpose": "Fetches the status of a specific task by its ID.",
          "documentation": "Provides the current status and details of a task, including timers and results."
        },
        {
          "name": "execute_task",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 256,
          "scope": "TaskManager",
          "purpose": "Executes the given task using the action manager.",
          "documentation": "Handles task resolution with required inputs, executes using the action manager, and stores results."
        },
        {
          "name": "handle_task_error",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 322,
          "scope": "TaskManager",
          "purpose": "Handles errors during task execution by generating new resolutions.",
          "documentation": "An error recovery method that attempts error resolution through new task generation."
        },
        {
          "name": "replan_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 350,
          "scope": "TaskManager",
          "purpose": "Replans tasks to achieve the goal state based on history.",
          "documentation": "Determines and generates new task plans for a goal by assessing partially completed tasks."
        },
        {
          "name": "handle_rerun_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 366,
          "scope": "TaskManager",
          "purpose": "Manages the rerun of tasks based on historical evaluation.",
          "documentation": "Evaluates necessity and recreates task sequences from a specified starting point to the current task."
        },
        {
          "name": "get_input_task_result",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 403,
          "scope": "TaskManager",
          "purpose": "Finds the result of a specific task based on its description.",
          "documentation": "Looks up and returns the result of a task using its exact or partial description match."
        },
        {
          "name": "has_pending_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 415,
          "scope": "TaskManager",
          "purpose": "Checks if there are any pending tasks and ensures they are queued.",
          "documentation": "Verifies pending status and possibly requeues tasks pending execution."
        },
        {
          "name": "get_pending_tasks",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 421,
          "scope": "TaskManager",
          "purpose": "Retrieves a list of all pending tasks.",
          "documentation": "Fetches tasks that are marked pending from the task dictionary."
        },
        {
          "name": "get_pending_task_count",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 426,
          "scope": "TaskManager",
          "purpose": "Returns the count of tasks pending in the queue.",
          "documentation": "Provides a quick count of all tasks currently waiting in the queue."
        },
        {
          "name": "log_task_queue_state",
          "type": "method",
          "file_path": "core/task_manager.py",
          "line_number": 429,
          "scope": "TaskManager",
          "purpose": "Logs the current state of the task queue.",
          "documentation": "Iterates through and logs all tasks present in the queue with their attributes."
        }
      ],
      "framework_hints": [
        "asyncio",
        "unittest.mock",
        "priority_queue_usage"
      ],
      "last_modified": "2025-02-08T21:11:35.591206",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "re",
          "typing.List",
          "typing.Dict",
          "typing.Any",
          "typing.Optional",
          "queue.PriorityQueue",
          "datetime.datetime",
          "uuid",
          "logging",
          "core.llm_interface.LLMInterface",
          "core.ethical_framework.EthicalFramework",
          "core.action_manager.ActionManager",
          "core.memory.Memory"
        ],
        "imported_by": []
      }
    },
    "Dockerfile": {
      "path": "Dockerfile",
      "language": "Unknown",
      "purpose": "This Dockerfile is used to set up a container environment for running a Python application that utilizes Playwright. It installs necessary packages and dependencies, exposes a network port, and defines the application's entry point.",
      "exposures": [
        {
          "name": "EXPOSE 8000",
          "type": "exposure",
          "file_path": "Dockerfile",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "python:v1.46.0-jammy (Playwright official image)",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "requirements.txt (Python packages)",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "Chromium (Playwright)",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "FROM",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 1,
          "scope": "global",
          "purpose": "Specifies the base image for the Docker container.",
          "documentation": "The Dockerfile starts with the Playwright Python base image version 1.46.0-jammy, which contains Python and Playwright pre-installed."
        },
        {
          "name": "WORKDIR",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 4,
          "scope": "/app",
          "purpose": "Sets the working directory in the Docker container.",
          "documentation": "Changes the working directory of the Docker container to /app, where subsequent instructions will be executed."
        },
        {
          "name": "COPY",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 7,
          "scope": "within /app",
          "purpose": "Copies files from the host to the Docker container.",
          "documentation": "The current directory contents ('.') are copied into the /app directory in the Docker container."
        },
        {
          "name": "RUN",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 10,
          "scope": "container setup",
          "purpose": "Executes commands in the Docker container.",
          "documentation": "This RUN command installs Python packages specified in requirements.txt without using cache."
        },
        {
          "name": "RUN",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 13,
          "scope": "container setup",
          "purpose": "Installs browser dependencies for Playwright.",
          "documentation": "Installs Chromium, which is needed for Playwright to run browser automation tasks."
        },
        {
          "name": "EXPOSE",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 16,
          "scope": "network",
          "purpose": "Declares the network port that the container will listen to.",
          "documentation": "Makes port 8000 available for connections to the Docker container from outside."
        },
        {
          "name": "CMD",
          "type": "directive",
          "file_path": "Dockerfile",
          "line_number": 19,
          "scope": "application entry point",
          "purpose": "Specifies the default command to run when the container starts.",
          "documentation": "Runs the Python script main.py when the Docker container is launched."
        }
      ],
      "framework_hints": [
        "Playwright",
        "Docker"
      ],
      "last_modified": "2025-02-08T21:12:01.899537",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "python:v1.46.0-jammy (Playwright official image)",
          "requirements.txt (Python packages)",
          "Chromium (Playwright)"
        ],
        "imported_by": []
      }
    },
    "requirements.txt": {
      "path": "requirements.txt",
      "language": "Unknown",
      "purpose": "Manage dependencies for a project involving HTTP requests, vector databases, retries, environment management, CLIs, CSV operations, AI functionalities, async operations, and API implementation.",
      "exposures": [],
      "dependencies": [
        {
          "name": "requests==2.26.0",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "qdrant-client==1.11.1",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "tenacity==8.0.1",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing-extensions==4.12.2",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "python-dotenv==0.19.2",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "pytest==7.0.1",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "click==8.0.3",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "pandas==1.3.5",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "openai==1.43.0",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "anthropic==0.34.2",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "playwright",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "googlesearch-python",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "markdownify",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "mistralai==1.1.0",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "aiohttp==3.10.10",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "fastapi==0.115.4",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "uvicorn==0.32.0",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [],
      "framework_hints": [
        "FastAPI for building APIs",
        "Uvicorn as an ASGI server for FastAPI",
        "pytest for testing",
        "pandas for data manipulation",
        "click for building command line interfaces",
        "aiohttp for handling async HTTP requests",
        "python-dotenv for environment variable management"
      ],
      "last_modified": "2025-02-08T21:12:01.900779",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "requests==2.26.0",
          "qdrant-client==1.11.1",
          "tenacity==8.0.1",
          "typing-extensions==4.12.2",
          "python-dotenv==0.19.2",
          "pytest==7.0.1",
          "click==8.0.3",
          "pandas==1.3.5",
          "openai==1.43.0",
          "anthropic==0.34.2",
          "playwright",
          "googlesearch-python",
          "markdownify",
          "mistralai==1.1.0",
          "aiohttp==3.10.10",
          "fastapi==0.115.4",
          "uvicorn==0.32.0"
        ],
        "imported_by": []
      }
    },
    "actions/memory_retrieval.py": {
      "path": "actions/memory_retrieval.py",
      "language": "Python",
      "purpose": "This module provides functions for interacting with a memory management system, allowing retrieval of recent memory, task results, and context from short-term and long-term memory.",
      "exposures": [
        {
          "name": "set_memory",
          "type": "exposure",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "retrieve_recent_memory",
          "type": "exposure",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "retrieve_task_result",
          "type": "exposure",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "retrieve_context_for_task",
          "type": "exposure",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "query_long_term_memory",
          "type": "exposure",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.memory",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "memory",
          "type": "variable",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 5,
          "scope": "module-level",
          "purpose": "Holds the memory instance for performing retrieval operations.",
          "documentation": "None"
        },
        {
          "name": "set_memory",
          "type": "function",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 7,
          "scope": "global",
          "purpose": "Sets the global memory variable to the provided memory instance.",
          "documentation": "This function assigns a given Memory instance to the global variable memory, enabling further memory operations."
        },
        {
          "name": "retrieve_recent_memory",
          "type": "function",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 13,
          "scope": "global",
          "purpose": "Retrieves a specified number of the most recent memory items.",
          "documentation": "Retrieves the n most recent items from short-term memory given by the Memory instance."
        },
        {
          "name": "retrieve_task_result",
          "type": "function",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 23,
          "scope": "global",
          "purpose": "Retrieves the result of a specific task from memory.",
          "documentation": "Retrieves the result of a task specified by task_description from memory, returning it in a dictionary format."
        },
        {
          "name": "retrieve_context_for_task",
          "type": "async function",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 33,
          "scope": "global",
          "purpose": "Asynchronously retrieves relevant context for a task from both short-term and long-term memory.",
          "documentation": "This function asynchronously retrieves relevant context for a task from memory, facilitating task-related operations."
        },
        {
          "name": "query_long_term_memory",
          "type": "async function",
          "file_path": "actions/memory_retrieval.py",
          "line_number": 44,
          "scope": "global",
          "purpose": "Asynchronously queries long-term memory based on a semantic similarity search.",
          "documentation": "Performs an asynchronous query on long-term memory based on the provided query string and limits the number of results returned."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:12:19.002838",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing",
          "core.memory"
        ],
        "imported_by": []
      }
    },
    "core/time_experience.py": {
      "path": "core/time_experience.py",
      "language": "Python",
      "purpose": "The primary purpose of the code is to simulate and manipulate the experience of time, allowing for accelerated or decelerated passage of time in a simulated environment.",
      "exposures": [
        {
          "name": "TimeExperience",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.__init__",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.update",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.get_current_time",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.get_elapsed_time",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.set_time_scale",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.sleep",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.format_time",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "TimeExperience.is_daytime",
          "type": "exposure",
          "file_path": "core/time_experience.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "time",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "datetime",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "TimeExperience",
          "type": "class",
          "file_path": "core/time_experience.py",
          "line_number": 5,
          "scope": null,
          "purpose": "Encapsulates time simulation functionality.",
          "documentation": "This class is responsible for managing the passage of time, allowing time scaling and providing time-related utilities."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 6,
          "scope": "TimeExperience",
          "purpose": "Initialize a TimeExperience instance with default values.",
          "documentation": "Sets the start time, current time, and initial time scale for the time experience."
        },
        {
          "name": "update",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 11,
          "scope": "TimeExperience",
          "purpose": "Update the current time based on the time scale.",
          "documentation": "Calculates the scaled elapsed time and updates the current time accordingly."
        },
        {
          "name": "get_current_time",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 16,
          "scope": "TimeExperience",
          "purpose": "Retrieve the current simulated time.",
          "documentation": "Returns the current time as a datetime object, accounting for any time scaling."
        },
        {
          "name": "get_elapsed_time",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 19,
          "scope": "TimeExperience",
          "purpose": "Calculate the elapsed time since the start.",
          "documentation": "Computes and returns the duration since the start time, adjusted for time scaling."
        },
        {
          "name": "set_time_scale",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 22,
          "scope": "TimeExperience",
          "purpose": "Set the multiplier for time passage.",
          "documentation": "Allows setting a positive factor to accelerate or decelerate time. Raises ValueError for non-positive values."
        },
        {
          "name": "sleep",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 28,
          "scope": "TimeExperience",
          "purpose": "Introduce a delay in simulated time.",
          "documentation": "Pauses execution for a duration scaled by the current time scale factor."
        },
        {
          "name": "format_time",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 32,
          "scope": "TimeExperience",
          "purpose": "Convert the current time to a formatted string.",
          "documentation": "Formats the current time using a provided format string, defaulting to a standard date-time format."
        },
        {
          "name": "is_daytime",
          "type": "method",
          "file_path": "core/time_experience.py",
          "line_number": 35,
          "scope": "TimeExperience",
          "purpose": "Check if the current time is during daylight hours.",
          "documentation": "Returns True if the hour of the current time falls between 6 AM and 6 PM; otherwise, returns False."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:12:42.895216",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "time",
          "datetime"
        ],
        "imported_by": []
      }
    },
    "core/sensor_manager.py": {
      "path": "core/sensor_manager.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to manage various sensors, handle their initialization, and process inputs from them asynchronously.",
      "exposures": [
        {
          "name": "SensorManager",
          "type": "exposure",
          "file_path": "core/sensor_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "initialize_sensors",
          "type": "exposure",
          "file_path": "core/sensor_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "register_sensor",
          "type": "exposure",
          "file_path": "core/sensor_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_input",
          "type": "exposure",
          "file_path": "core/sensor_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_available_sensors",
          "type": "exposure",
          "file_path": "core/sensor_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "sensors.sensor_base.Sensor",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "sensors.chat_interface.ChatInterface",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "SensorManager",
          "type": "class",
          "file_path": "core/sensor_manager.py",
          "line_number": 8,
          "scope": "global",
          "purpose": "Manages sensor initialization and input processing.",
          "documentation": "The SensorManager class is responsible for initializing sensors from the provided configuration, registering sensors, and retrieving processed inputs from the sensors asynchronously."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/sensor_manager.py",
          "line_number": 9,
          "scope": "SensorManager",
          "purpose": "Constructor for SensorManager.",
          "documentation": "Initializes the SensorManager instance with the provided configuration and sets up sensors."
        },
        {
          "name": "initialize_sensors",
          "type": "method",
          "file_path": "core/sensor_manager.py",
          "line_number": 13,
          "scope": "SensorManager",
          "purpose": "Initializes sensors based on configuration.",
          "documentation": "Sets up sensors based on the given configuration dictionary. Currently supports initializing a chat interface sensor."
        },
        {
          "name": "register_sensor",
          "type": "method",
          "file_path": "core/sensor_manager.py",
          "line_number": 20,
          "scope": "SensorManager",
          "purpose": "Registers a new sensor.",
          "documentation": "Allows manual registration of a sensor object with a specified name into the manager's sensors dictionary."
        },
        {
          "name": "get_input",
          "type": "method",
          "file_path": "core/sensor_manager.py",
          "line_number": 23,
          "scope": "SensorManager",
          "purpose": "Retrieves and processes input from all registered sensors.",
          "documentation": "Asynchronously fetches raw input from each sensor, processes the input, and returns a list of processed input data, each tagged with its sensor's name."
        },
        {
          "name": "get_available_sensors",
          "type": "method",
          "file_path": "core/sensor_manager.py",
          "line_number": 32,
          "scope": "SensorManager",
          "purpose": "Returns a list of available sensor names.",
          "documentation": "Provides a list of names of all currently registered sensors in the SensorManager."
        },
        {
          "name": "main",
          "type": "function",
          "file_path": "core/sensor_manager.py",
          "line_number": 35,
          "scope": "global",
          "purpose": "Demo function to run a test instance of SensorManager.",
          "documentation": "Asynchronously initializes a SensorManager, displays available sensors, and continuously retrieves and prints inputs from sensors until interrupted."
        }
      ],
      "framework_hints": [
        "asyncio"
      ],
      "last_modified": "2025-02-08T21:13:07.196937",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "asyncio",
          "typing",
          "sensors.sensor_base.Sensor",
          "sensors.chat_interface.ChatInterface"
        ],
        "imported_by": []
      }
    },
    "llm_providers/mistral_ai_provider.py": {
      "path": "llm_providers/mistral_ai_provider.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to provide an interface for interacting with the Mistral AI platform, specifically for generating text responses and embeddings based on given input prompts.",
      "exposures": [
        {
          "name": "MistralAIProvider.__init__",
          "type": "exposure",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "MistralAIProvider.generate",
          "type": "exposure",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "MistralAIProvider.get_embedding",
          "type": "exposure",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "mistralai",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "base_provider",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "MistralAIProvider",
          "type": "class",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 6,
          "scope": "global",
          "purpose": "This class serves as a provider for interacting with the Mistral AI for text generation and embedding retrieval.",
          "documentation": "MistralAIProvider is a class that implements text generation and embedding functionalities using Mistral AI services. It inherits from the BaseLLMProvider class."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 7,
          "scope": "MistralAIProvider",
          "purpose": "Initializes the MistralAIProvider with config parameters, sets up the Mistral client with an API key and model.",
          "documentation": "Constructor for MistralAIProvider. Accepts a configuration dictionary that provides the API key and optionally specifies the model to be used. Initializes the Mistral client and the model name."
        },
        {
          "name": "generate",
          "type": "method",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 11,
          "scope": "MistralAIProvider",
          "purpose": "Asynchronously generates a text response using the Mistral AI based on the provided prompt.",
          "documentation": "Generates a text response from the Mistral AI based on the input prompt. Utilizes the asynchronous method complete_async of the Mistral API client."
        },
        {
          "name": "get_embedding",
          "type": "method",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 21,
          "scope": "MistralAIProvider",
          "purpose": "Asynchronously retrieves an embedding for the input text using Mistral AI.",
          "documentation": "Fetches an embedding for the given text input using the Mistral AI embedding service. Utilizes the asynchronous method create_async from the Mistral API client."
        },
        {
          "name": "client",
          "type": "variable",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 8,
          "scope": "MistralAIProvider",
          "purpose": "Instance of the Mistral client to interface with the Mistral AI services.",
          "documentation": "Holds the Mistral client object initialized with the provided API key. It's used to interact with the Mistral API for generating text and embeddings."
        },
        {
          "name": "model",
          "type": "variable",
          "file_path": "llm_providers/mistral_ai_provider.py",
          "line_number": 9,
          "scope": "MistralAIProvider",
          "purpose": "Specifies which Mistral model to use for generating text responses.",
          "documentation": "Holds the model name from the provided configuration. Defaults to 'mistral-small-latest' if no model name is specified."
        }
      ],
      "framework_hints": [
        "asyncio"
      ],
      "last_modified": "2025-02-08T21:13:07.197484",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing",
          "mistralai",
          "base_provider"
        ],
        "imported_by": []
      }
    },
    "fluen_config.yml": {
      "path": "fluen_config.yml",
      "language": "Unknown",
      "purpose": "This configuration file sets up parameters related to caching, export options, language model details, and directories for a software application, likely involving AI or NLP processing using the OpenAI API.",
      "exposures": [],
      "dependencies": [
        {
          "name": "OpenAI API",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "cache_dir",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 1,
          "scope": "global",
          "purpose": "Specifies the directory where cache files are stored for the application.",
          "documentation": "Sets the path for caching mechanism to store temporary data, improving performance by avoiding redundant computation or data fetching."
        },
        {
          "name": "default_export_type",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 2,
          "scope": "global",
          "purpose": "Defines the default format for exporting results, likely related to how data or processed outputs are saved.",
          "documentation": "This variable specifies 'html' as the default format used by the system to export data, which would be interpretable in web browsers."
        },
        {
          "name": "llm",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 3,
          "scope": "global",
          "purpose": "Groups settings and parameters related to the language model configuration.",
          "documentation": "Contains several sub-properties that configure the language model, including retry handling, model selection (gpt-4o), provider details, timeout settings, and API authentication."
        },
        {
          "name": "max_retries",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 4,
          "scope": "llm",
          "purpose": "Sets the maximum number of retry attempts for API requests to handle transient failures.",
          "documentation": "Part of the 'llm' configuration, specifying that the system will attempt to resend failed requests up to 3 times before giving up."
        },
        {
          "name": "model",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 5,
          "scope": "llm",
          "purpose": "Specifies the model type or version to be used for processing language tasks.",
          "documentation": "Within 'llm', selects 'gpt-4o' as the model, indicating the use of a specific version or variant of GPT-4 from OpenAI."
        },
        {
          "name": "provider",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 6,
          "scope": "llm",
          "purpose": "Indicates the service provider for the language model.",
          "documentation": "This entry in the 'llm' setup specifies OpenAI as the provider of the language model services."
        },
        {
          "name": "timeout",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 7,
          "scope": "llm",
          "purpose": "Sets the maximum duration to wait for a single API request to complete before timing out.",
          "documentation": "In the 'llm' settings, a 60-second timeout is defined, after which API requests will be aborted to prevent hanging operations."
        },
        {
          "name": "api_key",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 8,
          "scope": "llm",
          "purpose": "Holds the API key used for authenticating requests to the OpenAI API.",
          "documentation": "Sensitive security information for accessing the OpenAI services, stored in plain text under 'llm'\u2014should be handled securely."
        },
        {
          "name": "output_dir",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 9,
          "scope": "global",
          "purpose": "Specifies the directory where the application's output files are stored.",
          "documentation": "Dictates the path ('docs') where exported or result data will be placed, aiding in organizing output results."
        },
        {
          "name": "temp_dir",
          "type": "variable",
          "file_path": "fluen_config.yml",
          "line_number": 10,
          "scope": "global",
          "purpose": "Specifies the directory for temporary files generated during processing.",
          "documentation": "Sets a directory for temporary storage (.fluen/temp) to be used during runtime, likely for data that doesn't need permanent storage."
        }
      ],
      "framework_hints": [
        "YAML configuration format"
      ],
      "last_modified": "2025-02-08T21:13:34.434874",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "OpenAI API"
        ],
        "imported_by": []
      }
    },
    "docker-compose.yml": {
      "path": "docker-compose.yml",
      "language": "Unknown",
      "purpose": "This Docker Compose file sets up a multi-container application environment with three services: jiva, qdrant, and ollama. It specifies configurations such as ports, volumes, and dependencies for these services.",
      "exposures": [
        {
          "name": "services.jiva",
          "type": "exposure",
          "file_path": "docker-compose.yml",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "services.qdrant",
          "type": "exposure",
          "file_path": "docker-compose.yml",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "services.ollama",
          "type": "exposure",
          "file_path": "docker-compose.yml",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "volumes.qdrant_storage",
          "type": "exposure",
          "file_path": "docker-compose.yml",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "volumes.ollama_models",
          "type": "exposure",
          "file_path": "docker-compose.yml",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "Docker",
          "type": "external",
          "version": null,
          "used_by": [
            "README.md"
          ]
        },
        {
          "name": "Docker Compose",
          "type": "external",
          "version": null,
          "used_by": [
            "README.md"
          ]
        }
      ],
      "elements": [
        {
          "name": "version",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 1,
          "scope": "global",
          "purpose": "Specifies the version of Docker Compose syntax being used.",
          "documentation": "The 'version' key defines which version of the Docker Compose file syntax is used."
        },
        {
          "name": "services",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 3,
          "scope": "global",
          "purpose": "Defines the services to be managed by Docker Compose.",
          "documentation": "The 'services' key is a dictionary where each key is the name of a service and its value is a definition of how that service should run."
        },
        {
          "name": "jiva",
          "type": "service",
          "file_path": "docker-compose.yml",
          "line_number": 4,
          "scope": "within services",
          "purpose": "Defines the 'jiva' microservice setup and configuration.",
          "documentation": "The 'jiva' service is built from the current directory, exposes port 8000, mounts local directories to the container, sets environment variables, and depends on the other two services."
        },
        {
          "name": "ports",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 6,
          "scope": "within jiva",
          "purpose": "Maps network ports inside a Docker container to ports on the host.",
          "documentation": "The 'ports' key specifies a mapping from host machine ports to container ports for network connectivity."
        },
        {
          "name": "volumes",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 8,
          "scope": "within jiva",
          "purpose": "Defines directory or file mounts from the host to the container.",
          "documentation": "Volumes are used for persisting data and sharing files between host and containers."
        },
        {
          "name": "environment",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 11,
          "scope": "within jiva",
          "purpose": "Sets environment variables in the Docker container.",
          "documentation": "The 'environment' section allows setting environment variables that the application running in the container can access."
        },
        {
          "name": "depends_on",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 15,
          "scope": "within jiva",
          "purpose": "Specifies dependencies between services.",
          "documentation": "The 'depends_on' key indicates that 'jiva' should start after 'qdrant' and 'ollama' are healthy and running."
        },
        {
          "name": "stdin_open",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 18,
          "scope": "within jiva",
          "purpose": "Keeps the standard input (stdin) open for interaction.",
          "documentation": "The 'stdin_open' key allows for interactive processes such as a console or a shell inside the container."
        },
        {
          "name": "tty",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 19,
          "scope": "within jiva",
          "purpose": "Allocates a pseudo-TTY for the container.",
          "documentation": "The 'tty' key enables a text interface for the container, which is useful for running terminal-based applications."
        },
        {
          "name": "command",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 20,
          "scope": "within jiva",
          "purpose": "Overrides the default command executed by the container.",
          "documentation": "The 'command' value runs a shell command sequence to ensure a configuration file exists and then starts a Python application."
        },
        {
          "name": "qdrant",
          "type": "service",
          "file_path": "docker-compose.yml",
          "line_number": 30,
          "scope": "within services",
          "purpose": "Service configuration for the Qdrant vector database.",
          "documentation": "The 'qdrant' service configuration specifies the image to run, port mapping, and volume usage."
        },
        {
          "name": "ollama",
          "type": "service",
          "file_path": "docker-compose.yml",
          "line_number": 36,
          "scope": "within services",
          "purpose": "Service configuration for the Ollama application.",
          "documentation": "The 'ollama' service configuration specifies the image to run, port mapping, and volume usage."
        },
        {
          "name": "volumes.qdrant_storage",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 43,
          "scope": "global",
          "purpose": "Defines a Docker volume for persisting Qdrant data.",
          "documentation": "The 'volumes.qdrant_storage' section specifies a named volume for storing data of the Qdrant service."
        },
        {
          "name": "volumes.ollama_models",
          "type": "variable",
          "file_path": "docker-compose.yml",
          "line_number": 44,
          "scope": "global",
          "purpose": "Defines a Docker volume for storing Ollama models.",
          "documentation": "The 'volumes.ollama_models' section specifies a named volume for storing model data of the Ollama service."
        }
      ],
      "framework_hints": [
        "Docker Compose"
      ],
      "last_modified": "2025-02-08T21:13:58.302137",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "Docker",
          "Docker Compose"
        ],
        "imported_by": []
      }
    },
    "sensors/sensor_base.py": {
      "path": "sensors/sensor_base.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to define an abstract base class for different types of sensors. This establishes a common interface for sensors to implement methods for receiving and processing input data.",
      "exposures": [
        {
          "name": "Sensor",
          "type": "exposure",
          "file_path": "sensors/sensor_base.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "abc",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "Sensor",
          "type": "class",
          "file_path": "sensors/sensor_base.py",
          "line_number": 6,
          "scope": "sensors/sensor_base.py",
          "purpose": "Defines an abstract base class for sensors requiring implementation of specific methods.",
          "documentation": "The Sensor class is an abstract base class (ABC) that defines the interface for sensor objects. It requires subclass implementations to provide logic for the 'get_input' and 'process_input' methods."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "sensors/sensor_base.py",
          "line_number": 7,
          "scope": "Sensor",
          "purpose": "Initializes a Sensor object with configuration settings.",
          "documentation": "The constructor method sets up the Sensor object by initializing a configuration dictionary, which can be used by subclasses to configure the sensor."
        },
        {
          "name": "get_input",
          "type": "method",
          "file_path": "sensors/sensor_base.py",
          "line_number": 11,
          "scope": "Sensor",
          "purpose": "An abstract method to be implemented for retrieving input from a sensor.",
          "documentation": "This asynchronous method is an abstract declaration, meant to be implemented in derived classes. It should define how the sensor retrieves its input data."
        },
        {
          "name": "process_input",
          "type": "method",
          "file_path": "sensors/sensor_base.py",
          "line_number": 18,
          "scope": "Sensor",
          "purpose": "An abstract method to be implemented for processing sensor input data.",
          "documentation": "This asynchronous method is an abstract declaration, meant to be implemented in derived classes. It should define how the raw input data is processed and returned in a suitable format for further use."
        }
      ],
      "framework_hints": [
        "asyncio",
        "abc module for abstract classes"
      ],
      "last_modified": "2025-02-08T21:14:12.224075",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "abc",
          "typing"
        ],
        "imported_by": []
      }
    },
    "actions/action_registry.py": {
      "path": "actions/action_registry.py",
      "language": "Python",
      "purpose": "This script serves as a registry for various actions by mapping action names to their respective functions. These actions are functionalities related to file operations, memory operations, thinking or planning tasks, and web interface interactions. The registry is used to standardize and centralize how actions are accessed and called in the system.",
      "exposures": [
        {
          "name": "get_action_registry",
          "type": "exposure",
          "file_path": "actions/action_registry.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing.Dict",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Callable",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing.Any",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.llm_interface.LLMInterface",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.memory.Memory",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "actions.file_operations",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "actions.memory_retrieval",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "actions.think",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "actions.web_interface",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "get_action_registry",
          "type": "function",
          "file_path": "actions/action_registry.py",
          "line_number": 15,
          "scope": "global",
          "purpose": "Provides a dictionary of action names mapped to their corresponding functions.",
          "documentation": "This function binds various actions with provided interfaces (LLMInterface and Memory) and returns a dictionary of action names to functions, allowing actions to be accessed by name."
        },
        {
          "name": "actions",
          "type": "variable",
          "file_path": "actions/action_registry.py",
          "line_number": 26,
          "scope": "local within get_action_registry",
          "purpose": "Stores the mapping of action names to their corresponding functions.",
          "documentation": "A dictionary variable that holds the mapping of action names to their corresponding callable functions. Its content is dynamically constructed based on the input parameters for LLMInterface and Memory, as well as imported actions."
        }
      ],
      "framework_hints": [],
      "last_modified": "2025-02-08T21:14:12.224371",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing.Dict",
          "typing.Callable",
          "typing.Any",
          "core.llm_interface.LLMInterface",
          "core.memory.Memory",
          "actions.file_operations",
          "actions.memory_retrieval",
          "actions.think",
          "actions.web_interface"
        ],
        "imported_by": []
      }
    },
    "README.md": {
      "path": "README.md",
      "language": "Unknown",
      "purpose": "The Jiva Framework is designed to run autonomous, goal-based agents using open-source language learning models (LLMs) on local machines, with optional support for proprietary models.",
      "exposures": [
        {
          "name": "config.json",
          "type": "exposure",
          "file_path": "README.md",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "docker-compose.yml",
          "type": "exposure",
          "file_path": "README.md",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "main.py",
          "type": "exposure",
          "file_path": "README.md",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "requirements.txt",
          "type": "exposure",
          "file_path": "README.md",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "Docker",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "Docker Compose",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "Python 3.7+",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "Ollama",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "Qdrant",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "OpenAI API (if using proprietary LLMs)",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "config.json",
          "type": "configuration file",
          "file_path": "README.md",
          "line_number": 0,
          "scope": "Project-wide",
          "purpose": "Defines configuration settings for running the Jiva framework, including the LLM provider and model settings.",
          "documentation": "This configuration file allows users to set their preferred LLM provider, whether open-source or proprietary, alongside other settings like API keys and model specifics."
        },
        {
          "name": "docker-compose.yml",
          "type": "configuration file",
          "file_path": "README.md",
          "line_number": 0,
          "scope": "Project-wide",
          "purpose": "Defines Docker services for deploying the Jiva framework and its dependencies.",
          "documentation": "Includes definitions for services like Qdrant, Ollama, and Jiva, outlining how to build and run these services in a Docker environment."
        },
        {
          "name": "main.py",
          "type": "entry point script",
          "file_path": "README.md",
          "line_number": 0,
          "scope": "Executable",
          "purpose": "Serves as the main entry point to start the Jiva agent.",
          "documentation": "This Python script is responsible for launching the Jiva framework, initiating the necessary components and processes for the AI agent to operate."
        },
        {
          "name": "requirements.txt",
          "type": "dependencies file",
          "file_path": "README.md",
          "line_number": 0,
          "scope": "Project-wide",
          "purpose": "Lists the Python packages required for running the Jiva framework.",
          "documentation": "This file specifies all Python dependencies needed, providing a way to install them using pip to ensure the environment is correctly set up."
        }
      ],
      "framework_hints": [
        "Docker Compose",
        "Python",
        "Qdrant vector database",
        "Ollama for LLM management"
      ],
      "last_modified": "2025-02-08T21:14:12.225062",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "Docker",
          "Docker Compose",
          "Python 3.7+",
          "Ollama",
          "Qdrant",
          "OpenAI API (if using proprietary LLMs)"
        ],
        "imported_by": []
      }
    },
    "api/main.py": {
      "path": "api/main.py",
      "language": "Python",
      "purpose": "This is a FastAPI application for managing and monitoring Jiva agents. It provides endpoints to check the status, goals, and tasks of the agent, create new goals, and trigger pending tasks.",
      "exposures": [
        {
          "name": "/status",
          "type": "exposure",
          "file_path": "api/main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "/goals",
          "type": "exposure",
          "file_path": "api/main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "/tasks",
          "type": "exposure",
          "file_path": "api/main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "/goal",
          "type": "exposure",
          "file_path": "api/main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "/about",
          "type": "exposure",
          "file_path": "api/main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "/trigger",
          "type": "exposure",
          "file_path": "api/main.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "fastapi",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "datetime",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "app",
          "type": "variable",
          "file_path": "api/main.py",
          "line_number": 9,
          "scope": "global",
          "purpose": "FastAPI application instance.",
          "documentation": "Initialized FastAPI app with metadata such as title, description, and version."
        },
        {
          "name": "logger",
          "type": "variable",
          "file_path": "api/main.py",
          "line_number": 18,
          "scope": "global",
          "purpose": "Logger instance for the API.",
          "documentation": "Logger used for recording errors and other messages in the application."
        },
        {
          "name": "get_agent",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 20,
          "scope": "global",
          "purpose": "Fetches the agent instance from the FastAPI app state.",
          "documentation": "Dependency to get the agent instance. Raises HTTP 503 error if the agent is not initialized."
        },
        {
          "name": "get_status",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 27,
          "scope": "global",
          "purpose": "Endpoint to return the current status of the Jiva agent.",
          "documentation": "Checks if there are pending tasks and returns the agent's current status, goal, and pending tasks."
        },
        {
          "name": "get_goals",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 45,
          "scope": "global",
          "purpose": "Endpoint to retrieve a list of all goals managed by the agent.",
          "documentation": "Returns goals with their status and sorts them by creation time, newest first."
        },
        {
          "name": "get_tasks",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 63,
          "scope": "global",
          "purpose": "Endpoint to get a list of tasks, optionally filtered by a goal.",
          "documentation": "Fetches tasks from the agent and returns them, sorted by creation time, newest first."
        },
        {
          "name": "create_goal",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 83,
          "scope": "global",
          "purpose": "Endpoint to create a new goal for the Jiva agent.",
          "documentation": "Processes a goal input and returns the initial set of generated tasks related to the goal."
        },
        {
          "name": "get_about",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 113,
          "scope": "global",
          "purpose": "Endpoint to get information about the agent configuration.",
          "documentation": "Prints the configuration, available actions, and sensors, masking any sensitive data like API keys."
        },
        {
          "name": "generic_exception_handler",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 146,
          "scope": "global",
          "purpose": "Global exception handler for the application.",
          "documentation": "Logs unhandled exceptions and returns a generic HTTP 500 response to the client."
        },
        {
          "name": "trigger_agent",
          "type": "function",
          "file_path": "api/main.py",
          "line_number": 151,
          "scope": "global",
          "purpose": "Endpoint to trigger the agent to execute pending tasks.",
          "documentation": "Requeues pending tasks and signals the agent to start task execution."
        }
      ],
      "framework_hints": [
        "FastAPI"
      ],
      "last_modified": "2025-02-08T21:14:38.496093",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "asyncio",
          "fastapi",
          "logging",
          "datetime"
        ],
        "imported_by": []
      }
    },
    "llm_providers/openai_provider.py": {
      "path": "llm_providers/openai_provider.py",
      "language": "Python",
      "purpose": "This code defines a provider class for interacting with the OpenAI API asynchronously, specifically to generate text and obtain embeddings from a given input.",
      "exposures": [
        {
          "name": "OpenAIProvider",
          "type": "exposure",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "openai",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": ".base_provider",
          "type": "internal",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "OpenAIProvider",
          "type": "class",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 6,
          "scope": "global",
          "purpose": "To provide methods for generating text and obtaining embeddings using the OpenAI API.",
          "documentation": "OpenAIProvider inherits from BaseLLMProvider and uses the OpenAI API for generating text completions and embeddings asynchronously."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 7,
          "scope": "OpenAIProvider",
          "purpose": "Initializes the OpenAIProvider with configuration for API access.",
          "documentation": "Constructor for OpenAIProvider that initializes the AsyncOpenAI client with the provided API key and sets the model to be used for generating text."
        },
        {
          "name": "generate",
          "type": "method",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 12,
          "scope": "OpenAIProvider",
          "purpose": "Generates a text completion from a given prompt using the OpenAI API.",
          "documentation": "Asynchronous method to generate a text response from OpenAI's model based on the input prompt. It uses chat completions to fetch the output."
        },
        {
          "name": "get_embedding",
          "type": "method",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 19,
          "scope": "OpenAIProvider",
          "purpose": "Generates an embedding vector from a given text input using the OpenAI API.",
          "documentation": "Asynchronous method to retrieve an embedding for the given input text using the specified OpenAI model."
        },
        {
          "name": "client",
          "type": "variable",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 8,
          "scope": "OpenAIProvider",
          "purpose": "Holds the instance of AsyncOpenAI client for API communication.",
          "documentation": "Instance of AsyncOpenAI created during the initialization of OpenAIProvider with a given API key."
        },
        {
          "name": "model",
          "type": "variable",
          "file_path": "llm_providers/openai_provider.py",
          "line_number": 9,
          "scope": "OpenAIProvider",
          "purpose": "Stores the name of the model to be used for API requests.",
          "documentation": "This variable stores the model name for generating text completions, defaulting to 'gpt-3.5-turbo' if not specified in the config."
        }
      ],
      "framework_hints": [
        "Python",
        "asyncio"
      ],
      "last_modified": "2025-02-08T21:14:38.497598",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "openai",
          "typing",
          ".base_provider"
        ],
        "imported_by": []
      }
    },
    "sensors/chat_interface.py": {
      "path": "sensors/chat_interface.py",
      "language": "Python",
      "purpose": "This code defines a class ChatInterface that extends the Sensor class to provide a command-line interface for capturing and processing user input asynchronously.",
      "exposures": [
        {
          "name": "ChatInterface",
          "type": "exposure",
          "file_path": "sensors/chat_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_input",
          "type": "exposure",
          "file_path": "sensors/chat_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "process_input",
          "type": "exposure",
          "file_path": "sensors/chat_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_timestamp",
          "type": "exposure",
          "file_path": "sensors/chat_interface.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "sys",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "select",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "sensor_base.Sensor",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "ChatInterface",
          "type": "class",
          "file_path": "sensors/chat_interface.py",
          "line_number": 9,
          "scope": "module level",
          "purpose": "To manage asynchronous non-blocking input from the command-line interface.",
          "documentation": "ChatInterface extends Sensor and provides methods to capture and process user input asynchronously on different platforms."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "sensors/chat_interface.py",
          "line_number": 11,
          "scope": "ChatInterface",
          "purpose": "Initialize ChatInterface with a configuration dictionary and set up the prompt.",
          "documentation": "The constructor receives a config dictionary, calls the parent constructor, and sets up a command prompt for the interface."
        },
        {
          "name": "get_input",
          "type": "method",
          "file_path": "sensors/chat_interface.py",
          "line_number": 16,
          "scope": "ChatInterface",
          "purpose": "Check for user input asynchronously without blocking the command-line interface.",
          "documentation": "Depending on the OS, it uses different methods to non-blockingly check for user input and return it if available."
        },
        {
          "name": "_get_input_unix",
          "type": "method",
          "file_path": "sensors/chat_interface.py",
          "line_number": 23,
          "scope": "ChatInterface",
          "purpose": "Handle non-blocking user input on Unix-like systems.",
          "documentation": "Uses select to check for any input on stdin and returns the input if available."
        },
        {
          "name": "_get_input_windows",
          "type": "method",
          "file_path": "sensors/chat_interface.py",
          "line_number": 30,
          "scope": "ChatInterface",
          "purpose": "Handle non-blocking user input on Windows systems.",
          "documentation": "Uses asyncio to run an executor that checks for input, as Windows does not support select on stdin."
        },
        {
          "name": "process_input",
          "type": "method",
          "file_path": "sensors/chat_interface.py",
          "line_number": 47,
          "scope": "ChatInterface",
          "purpose": "Transform the raw input data into a structured format.",
          "documentation": "Takes input data from the user and returns it structured with metadata like type and timestamp."
        },
        {
          "name": "get_timestamp",
          "type": "method",
          "file_path": "sensors/chat_interface.py",
          "line_number": 55,
          "scope": "ChatInterface",
          "purpose": "Generate a current timestamp string in ISO format.",
          "documentation": "Uses datetime to return a string representing the current time in ISO 8601 format."
        }
      ],
      "framework_hints": [
        "asyncio (for async functionality)"
      ],
      "last_modified": "2025-02-08T21:14:50.005229",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "asyncio",
          "sys",
          "select",
          "typing",
          "sensor_base.Sensor"
        ],
        "imported_by": []
      }
    },
    "actions/think.py": {
      "path": "actions/think.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to provide an interface for generating responses using a large language model (LLM) via a reusable asynchronous 'think' function and several utility functions for task management.",
      "exposures": [
        {
          "name": "set_llm_interface",
          "type": "exposure",
          "file_path": "actions/think.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "think",
          "type": "exposure",
          "file_path": "actions/think.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "replan_tasks",
          "type": "exposure",
          "file_path": "actions/think.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "sleep",
          "type": "exposure",
          "file_path": "actions/think.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "rerun_tasks",
          "type": "exposure",
          "file_path": "actions/think.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "asyncio",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.llm_interface",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "llm_interface",
          "type": "variable",
          "file_path": "actions/think.py",
          "line_number": 6,
          "scope": "global",
          "purpose": "Stores an instance of the LLMInterface, used to interact with a large language model.",
          "documentation": "Global variable intended to hold an LLMInterface object for use by other functions."
        },
        {
          "name": "set_llm_interface",
          "type": "function",
          "file_path": "actions/think.py",
          "line_number": 8,
          "scope": "global",
          "purpose": "Sets the global LLM interface used to generate responses.",
          "documentation": "This function takes an LLMInterface object as an argument and assigns it to the global 'llm_interface' variable."
        },
        {
          "name": "think",
          "type": "function",
          "file_path": "actions/think.py",
          "line_number": 13,
          "scope": "global",
          "purpose": "Asynchronously generates a response from the LLM based on prompt and optional context.",
          "documentation": "Uses the LLM to generate a response. The context is concatenated with the prompt and sent to the LLM via the 'llm_interface.generate' method."
        },
        {
          "name": "replan_tasks",
          "type": "function",
          "file_path": "actions/think.py",
          "line_number": 30,
          "scope": "global",
          "purpose": "Placeholder function for task replanning.",
          "documentation": "Asynchronous function that returns an empty string, serves as a marker for where tasks need replanning."
        },
        {
          "name": "sleep",
          "type": "function",
          "file_path": "actions/think.py",
          "line_number": 38,
          "scope": "global",
          "purpose": "Pauses task execution for a specified number of seconds.",
          "documentation": "Asynchronous function that uses asyncio.sleep to pause for a specified time, then returns an empty string."
        },
        {
          "name": "rerun_tasks",
          "type": "function",
          "file_path": "actions/think.py",
          "line_number": 48,
          "scope": "global",
          "purpose": "Marks a task as the point to resume execution.",
          "documentation": "Asynchronous function that takes the name of a task and returns it, indicating where execution should resume."
        }
      ],
      "framework_hints": [
        "asyncio (Python's standard library for asynchronous programming)"
      ],
      "last_modified": "2025-02-08T21:15:15.634953",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "asyncio",
          "typing",
          "core.llm_interface"
        ],
        "imported_by": []
      }
    },
    "core/action_manager.py": {
      "path": "core/action_manager.py",
      "language": "Python",
      "purpose": "The primary purpose of this code is to manage and execute actions in an ethical manner by evaluating them through an ethical framework before performing them.",
      "exposures": [
        {
          "name": "execute_action",
          "type": "exposure",
          "file_path": "core/action_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_available_actions",
          "type": "exposure",
          "file_path": "core/action_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        },
        {
          "name": "get_action_ethical_summary",
          "type": "exposure",
          "file_path": "core/action_manager.py",
          "line_number": 0,
          "scope": null,
          "purpose": null,
          "documentation": null
        }
      ],
      "dependencies": [
        {
          "name": "typing",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "logging",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.ethical_framework.EthicalFramework",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.memory.Memory",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "core.llm_interface.LLMInterface",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "actions.action_registry.get_action_registry",
          "type": "external",
          "version": null,
          "used_by": null
        },
        {
          "name": "inspect",
          "type": "external",
          "version": null,
          "used_by": null
        }
      ],
      "elements": [
        {
          "name": "ActionManager",
          "type": "class",
          "file_path": "core/action_manager.py",
          "line_number": 9,
          "scope": "global",
          "purpose": "Manages and executes registered actions with ethical evaluations.",
          "documentation": "A class responsible for handling the execution of actions after ensuring they pass ethical evaluations."
        },
        {
          "name": "__init__",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 10,
          "scope": "ActionManager",
          "purpose": "Initializes the ActionManager with an ethical framework, memory, and LLM interface.",
          "documentation": "Constructor that sets up dependencies and retrieves the action registry."
        },
        {
          "name": "execute_action",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 17,
          "scope": "ActionManager",
          "purpose": "Executes a registered action after ethical evaluation.",
          "documentation": "Attempts to execute an action if it is found to be ethical. Handles execution errors and records the action in memory."
        },
        {
          "name": "get_available_actions",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 50,
          "scope": "ActionManager",
          "purpose": "Retrieves all registered actions with their descriptions and parameters.",
          "documentation": "Returns a dictionary containing information about available actions, including their docstring description and parameters."
        },
        {
          "name": "_get_function_parameters",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 59,
          "scope": "ActionManager",
          "purpose": "Extracts parameter names and annotations from a given function.",
          "documentation": "Uses the inspect module to retrieve and return the names and annotated types of parameters for a function."
        },
        {
          "name": "get_action_ethical_summary",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 67,
          "scope": "ActionManager",
          "purpose": "Provides an ethical summary of a particular action.",
          "documentation": "Checks if an action is ethical and provides an explanation, including its parameters."
        },
        {
          "name": "MockEthicalFramework",
          "type": "class",
          "file_path": "core/action_manager.py",
          "line_number": 77,
          "scope": "local",
          "purpose": "Mock class for testing the ethical evaluation of actions.",
          "documentation": "A simple mock implementation of EthicalFramework used to simulate the behavior of real ethical evaluations."
        },
        {
          "name": "evaluate_action",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 78,
          "scope": "MockEthicalFramework",
          "purpose": "Mock method to evaluate if an action is ethical.",
          "documentation": "Determines if an action should be considered ethical based on hardcoded logic."
        },
        {
          "name": "get_ethical_explanation",
          "type": "method",
          "file_path": "core/action_manager.py",
          "line_number": 80,
          "scope": "MockEthicalFramework",
          "purpose": "Provides an explanation for the mock ethical evaluation.",
          "documentation": "Returns a reason why an action is ethical or unethical for testing purposes."
        }
      ],
      "framework_hints": [
        "asyncio",
        "unittest.mock"
      ],
      "last_modified": "2025-02-08T21:15:15.635167",
      "relationships": {
        "dependencies": [],
        "dependents": [],
        "imports": [
          "typing",
          "logging",
          "core.ethical_framework.EthicalFramework",
          "core.memory.Memory",
          "core.llm_interface.LLMInterface",
          "actions.action_registry.get_action_registry",
          "inspect"
        ],
        "imported_by": []
      }
    }
  },
  "dependencies": {
    "typing": {
      "name": "typing",
      "type": "external",
      "version": null,
      "used_by": [
        "actions/file_operations.py",
        "main.py",
        "core/memory.py",
        "llm_providers/anthropic_provider.py",
        "core/llm_interface.py",
        "llm_providers/ollama_provider.py",
        "llm_providers/base_provider.py",
        "actions/memory_retrieval.py",
        "core/sensor_manager.py",
        "llm_providers/mistral_ai_provider.py",
        "sensors/sensor_base.py",
        "llm_providers/openai_provider.py",
        "sensors/chat_interface.py",
        "actions/think.py",
        "core/action_manager.py"
      ]
    },
    "bs4": {
      "name": "bs4",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "playwright": {
      "name": "playwright",
      "type": "external",
      "version": null,
      "used_by": [
        "requirements.txt"
      ]
    },
    "aiohttp": {
      "name": "aiohttp",
      "type": "external",
      "version": null,
      "used_by": [
        "llm_providers/anthropic_provider.py",
        "llm_providers/ollama_provider.py"
      ]
    },
    "googlesearch": {
      "name": "googlesearch",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "markdownify": {
      "name": "markdownify",
      "type": "external",
      "version": null,
      "used_by": [
        "requirements.txt"
      ]
    },
    "logging": {
      "name": "logging",
      "type": "external",
      "version": null,
      "used_by": [
        "actions/file_operations.py",
        "main.py",
        "core/memory.py",
        "core/llm_interface.py",
        "core/ethical_framework.py",
        "core/agent.py",
        "utils/qdrant_handler.py",
        "core/task_manager.py",
        "api/main.py",
        "core/action_manager.py"
      ]
    },
    "asyncio": {
      "name": "asyncio",
      "type": "external",
      "version": null,
      "used_by": [
        "actions/file_operations.py",
        "main.py",
        "core/agent.py",
        "core/sensor_manager.py",
        "api/main.py",
        "sensors/chat_interface.py",
        "actions/think.py"
      ]
    },
    "core.llm_interface": {
      "name": "core.llm_interface",
      "type": "external",
      "version": null,
      "used_by": [
        "actions/think.py"
      ]
    },
    "os": {
      "name": "os",
      "type": "external",
      "version": null,
      "used_by": [
        "main.py",
        "core/agent.py"
      ]
    },
    "json": {
      "name": "json",
      "type": "external",
      "version": null,
      "used_by": [
        "main.py",
        "core/memory.py",
        "llm_providers/anthropic_provider.py",
        "core/llm_interface.py",
        "core/agent.py",
        "llm_providers/ollama_provider.py",
        "models/embeddings.py"
      ]
    },
    "csv": {
      "name": "csv",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "uvicorn": {
      "name": "uvicorn",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "api.main": {
      "name": "api.main",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "core.agent": {
      "name": "core.agent",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "actions.action_registry": {
      "name": "actions.action_registry",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "None (This is a license, not a code)": {
      "name": "None (This is a license, not a code)",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "datetime": {
      "name": "datetime",
      "type": "external",
      "version": null,
      "used_by": [
        "core/agent.py",
        "core/time_experience.py",
        "api/main.py"
      ]
    },
    "core.llm_interface.LLMInterface": {
      "name": "core.llm_interface.LLMInterface",
      "type": "external",
      "version": null,
      "used_by": [
        "core/ethical_framework.py",
        "core/task_manager.py",
        "actions/action_registry.py",
        "core/action_manager.py"
      ]
    },
    "utils.qdrant_handler.QdrantHandler": {
      "name": "utils.qdrant_handler.QdrantHandler",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant": {
      "name": "qdrant",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "ollama": {
      "name": "ollama",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "mistralai": {
      "name": "mistralai",
      "type": "external",
      "version": null,
      "used_by": [
        "llm_providers/mistral_ai_provider.py"
      ]
    },
    "anthropic.AsyncAnthropic": {
      "name": "anthropic.AsyncAnthropic",
      "type": "external",
      "version": null,
      "used_by": null
    },
    ".base_provider.BaseLLMProvider": {
      "name": ".base_provider.BaseLLMProvider",
      "type": "internal",
      "version": null,
      "used_by": null
    },
    "re": {
      "name": "re",
      "type": "external",
      "version": null,
      "used_by": [
        "core/task_manager.py"
      ]
    },
    "tenacity": {
      "name": "tenacity",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "llm_providers.base_provider": {
      "name": "llm_providers.base_provider",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "llm_providers.ollama_provider": {
      "name": "llm_providers.ollama_provider",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "llm_providers.openai_provider": {
      "name": "llm_providers.openai_provider",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "llm_providers.anthropic_provider": {
      "name": "llm_providers.anthropic_provider",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "llm_providers.mistral_ai_provider": {
      "name": "llm_providers.mistral_ai_provider",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "typing.List": {
      "name": "typing.List",
      "type": "external",
      "version": null,
      "used_by": [
        "utils/qdrant_handler.py",
        "core/task_manager.py"
      ]
    },
    "typing.Dict": {
      "name": "typing.Dict",
      "type": "external",
      "version": null,
      "used_by": [
        "utils/qdrant_handler.py",
        "core/task_manager.py",
        "actions/action_registry.py"
      ]
    },
    "typing.Any": {
      "name": "typing.Any",
      "type": "external",
      "version": null,
      "used_by": [
        "utils/qdrant_handler.py",
        "core/task_manager.py",
        "actions/action_registry.py"
      ]
    },
    "typing.Union": {
      "name": "typing.Union",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "RotatingFileHandler": {
      "name": "RotatingFileHandler",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "Memory": {
      "name": "Memory",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "TimeExperience": {
      "name": "TimeExperience",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "TaskManager": {
      "name": "TaskManager",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "EthicalFramework": {
      "name": "EthicalFramework",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "LLMInterface": {
      "name": "LLMInterface",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "SensorManager": {
      "name": "SensorManager",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "ActionManager": {
      "name": "ActionManager",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "base_provider": {
      "name": "base_provider",
      "type": "external",
      "version": null,
      "used_by": [
        "llm_providers/mistral_ai_provider.py"
      ]
    },
    "java": {
      "name": "java",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "requests": {
      "name": "requests",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.AsyncQdrantClient": {
      "name": "qdrant_client.AsyncQdrantClient",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.http.models.Distance": {
      "name": "qdrant_client.http.models.Distance",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.http.models.VectorParams": {
      "name": "qdrant_client.http.models.VectorParams",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.http.models.PointStruct": {
      "name": "qdrant_client.http.models.PointStruct",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.http.models.UpdateStatus": {
      "name": "qdrant_client.http.models.UpdateStatus",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.http.exceptions.ResponseHandlingException": {
      "name": "qdrant_client.http.exceptions.ResponseHandlingException",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant_client.http.exceptions.UnexpectedResponse": {
      "name": "qdrant_client.http.exceptions.UnexpectedResponse",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "uuid": {
      "name": "uuid",
      "type": "external",
      "version": null,
      "used_by": [
        "core/task_manager.py"
      ]
    },
    "abc": {
      "name": "abc",
      "type": "external",
      "version": null,
      "used_by": [
        "sensors/sensor_base.py"
      ]
    },
    "typing.Optional": {
      "name": "typing.Optional",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "queue.PriorityQueue": {
      "name": "queue.PriorityQueue",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "datetime.datetime": {
      "name": "datetime.datetime",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "core.ethical_framework.EthicalFramework": {
      "name": "core.ethical_framework.EthicalFramework",
      "type": "external",
      "version": null,
      "used_by": [
        "core/action_manager.py"
      ]
    },
    "core.action_manager.ActionManager": {
      "name": "core.action_manager.ActionManager",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "core.memory.Memory": {
      "name": "core.memory.Memory",
      "type": "external",
      "version": null,
      "used_by": [
        "actions/action_registry.py",
        "core/action_manager.py"
      ]
    },
    "python:v1.46.0-jammy (Playwright official image)": {
      "name": "python:v1.46.0-jammy (Playwright official image)",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "requirements.txt (Python packages)": {
      "name": "requirements.txt (Python packages)",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "Chromium (Playwright)": {
      "name": "Chromium (Playwright)",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "requests==2.26.0": {
      "name": "requests==2.26.0",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "qdrant-client==1.11.1": {
      "name": "qdrant-client==1.11.1",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "tenacity==8.0.1": {
      "name": "tenacity==8.0.1",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "typing-extensions==4.12.2": {
      "name": "typing-extensions==4.12.2",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "python-dotenv==0.19.2": {
      "name": "python-dotenv==0.19.2",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "pytest==7.0.1": {
      "name": "pytest==7.0.1",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "click==8.0.3": {
      "name": "click==8.0.3",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "pandas==1.3.5": {
      "name": "pandas==1.3.5",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "openai==1.43.0": {
      "name": "openai==1.43.0",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "anthropic==0.34.2": {
      "name": "anthropic==0.34.2",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "googlesearch-python": {
      "name": "googlesearch-python",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "mistralai==1.1.0": {
      "name": "mistralai==1.1.0",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "aiohttp==3.10.10": {
      "name": "aiohttp==3.10.10",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "fastapi==0.115.4": {
      "name": "fastapi==0.115.4",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "uvicorn==0.32.0": {
      "name": "uvicorn==0.32.0",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "core.memory": {
      "name": "core.memory",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "time": {
      "name": "time",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "sensors.sensor_base.Sensor": {
      "name": "sensors.sensor_base.Sensor",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "sensors.chat_interface.ChatInterface": {
      "name": "sensors.chat_interface.ChatInterface",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "OpenAI API": {
      "name": "OpenAI API",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "Docker": {
      "name": "Docker",
      "type": "external",
      "version": null,
      "used_by": [
        "README.md"
      ]
    },
    "Docker Compose": {
      "name": "Docker Compose",
      "type": "external",
      "version": null,
      "used_by": [
        "README.md"
      ]
    },
    "typing.Callable": {
      "name": "typing.Callable",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "actions.file_operations": {
      "name": "actions.file_operations",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "actions.memory_retrieval": {
      "name": "actions.memory_retrieval",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "actions.think": {
      "name": "actions.think",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "actions.web_interface": {
      "name": "actions.web_interface",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "Python 3.7+": {
      "name": "Python 3.7+",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "Ollama": {
      "name": "Ollama",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "Qdrant": {
      "name": "Qdrant",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "OpenAI API (if using proprietary LLMs)": {
      "name": "OpenAI API (if using proprietary LLMs)",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "fastapi": {
      "name": "fastapi",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "openai": {
      "name": "openai",
      "type": "external",
      "version": null,
      "used_by": null
    },
    ".base_provider": {
      "name": ".base_provider",
      "type": "internal",
      "version": null,
      "used_by": null
    },
    "sys": {
      "name": "sys",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "select": {
      "name": "select",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "sensor_base.Sensor": {
      "name": "sensor_base.Sensor",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "actions.action_registry.get_action_registry": {
      "name": "actions.action_registry.get_action_registry",
      "type": "external",
      "version": null,
      "used_by": null
    },
    "inspect": {
      "name": "inspect",
      "type": "external",
      "version": null,
      "used_by": null
    }
  },
  "last_updated": "2025-02-08T21:15:17.638431",
  "git_commit": "fe577ea54ef245da4b80b33846e5db8f01a8e564",
  "project_insights": {
    "overview": "The **Jiva Framework** is a powerful AI-driven framework that allows for the creation and management of autonomous, goal-based agents utilizing open-source Language Learning Models (LLMs) on local machines. It offers optional support for integrating proprietary models like OpenAI, Mistral AI, and Anthropic. Jiva provides robust systems for asynchronous operations, memory management, ethical task evaluations, and seamless API integration through FastAPI. The framework is designed to support autonomous systems in performing complex tasks while ensuring ethical compliance and efficient resource utilization.",
    "key_features": [
      {
        "name": "Asynchronous Operations",
        "description": "Utilizes Python's `asyncio` along with `aiohttp` for handling asynchronous operations, allowing efficient I/O-bound task execution and management.",
        "category": "Core",
        "status": "Implemented"
      },
      {
        "name": "Memory Management",
        "description": "Incorporates a sophisticated memory management system to handle short-term and long-term memory using semantic embeddings and a connection to a Qdrant vector database.",
        "category": "Core",
        "status": "Implemented"
      },
      {
        "name": "Ethical Task Evaluation",
        "description": "Implements an ethical framework to evaluate and prioritize tasks based on predefined principles, ensuring actions adhere to ethical standards.",
        "category": "Core",
        "status": "Implemented"
      },
      {
        "name": "API Integration",
        "description": "Leverages FastAPI and Uvicorn for building and serving APIs, providing endpoints to manage and monitor Jiva agents and their tasks.",
        "category": "Integration",
        "status": "Implemented"
      },
      {
        "name": "Dockerized Deployment",
        "description": "Supports Docker and Docker Compose for containerized deployment, allowing consistent application setup and environment management.",
        "category": "Integration",
        "status": "Implemented"
      },
      {
        "name": "Web Search and Interface",
        "description": "Provides an interface for conducting web searches, visiting pages, and extracting relevant content asynchronously using language models.",
        "category": "Integration",
        "status": "Implemented"
      },
      {
        "name": "Command Line Interface",
        "description": "Includes a CLI tool built with `click` for command line interactions, facilitating easy management and deployment of agents.",
        "category": "UI",
        "status": "Implemented"
      },
      {
        "name": "Test and Validation Framework",
        "description": "Integrates `pytest` for testing functionalities, ensuring the reliability and correctness of implemented features.",
        "category": "Core",
        "status": "Implemented"
      }
    ],
    "architecture": {
      "summary": "The **Jiva** project is an advanced autonomous agent framework implemented primarily using **Python**. It employs asynchronous programming heavily with a focus on APIs, task management, and integration with various language models (LLMs). The architecture is modular, with a clean separation of concerns across components such as API management, agent execution, memory handling, and ethical evaluations using a multi-container setup via Docker and Docker Compose.",
      "design_patterns": [
        {
          "name": "Asynchronous Programming",
          "purpose": "To handle multiple concurrent operations efficiently, allowing the system to perform tasks like web scraping and API calls without blocking.",
          "location": "Implemented using `asyncio`, `aiohttp`, and integrated across the system for file operations, web interactions, and API requests."
        },
        {
          "name": "Strategy Pattern",
          "purpose": "To select different language model providers at runtime based on configuration and needs.",
          "location": "Located in `llm_providers` where different LLM API providers like OpenAI, Anthropic, etc., are implemented."
        },
        {
          "name": "Dependency Injection",
          "purpose": "For managing and injecting dependencies, especially LLM providers and configuration options.",
          "location": "Configuration files like `config.json` and example setup in various provider classes."
        },
        {
          "name": "Observer Pattern",
          "purpose": "To react to sensor data inputs in real-time, allowing the agent to respond to changes in its environment.",
          "location": "In `core/sensor_manager.py`, where different sensors contribute data."
        }
      ],
      "primary_components": [
        {
          "name": "Jiva Agent",
          "responsibility": "Act as the core autonomous agent handling tasks, managing memory, and executing actions based on sensor inputs.",
          "dependencies": [
            "core.memory",
            "core.ethical_framework",
            "core.task_manager"
          ],
          "key_files": [
            "core/agent.py",
            "core/task_manager.py",
            "core/memory.py"
          ]
        },
        {
          "name": "API Layer",
          "responsibility": "Provide HTTP endpoints to interact with and monitor the agent, allowing control and configuration from external systems.",
          "dependencies": [
            "FastAPI",
            "Uvicorn"
          ],
          "key_files": [
            "api/main.py"
          ]
        },
        {
          "name": "LLM Providers",
          "responsibility": "Abstract interaction with various language model APIs providing functionalities like text generation and embeddings.",
          "dependencies": [
            "OpenAI API",
            "Anthropic",
            "Ollama",
            "Qdrant"
          ],
          "key_files": [
            "llm_providers/openai_provider.py",
            "llm_providers/anthropic_provider.py"
          ]
        },
        {
          "name": "Memory Management",
          "responsibility": "Handle short-term and long-term memory operations using semantic embeddings and database interactions.",
          "dependencies": [
            "Qdrant vector database",
            "utils.qdrant_handler"
          ],
          "key_files": [
            "core/memory.py",
            "utils/qdrant_handler.py"
          ]
        }
      ],
      "data_flow": {
        "description": "Data flows through the Jiva framework starting from sensor inputs processed asynchronously, feeding into the task manager and memory systems. These inputs trigger tasks and actions which may fetch or push data to external LLMs or databases. The results are gathered and stored in short-term memory, later consolidated into long-term storage. The API layer facilitates external interaction, allowing status checks and task submissions.",
        "key_processes": [
          "Receive and process input asynchronously via sensors",
          "Manage tasks with priority and dependencies",
          "Perform actions evaluated against the ethical framework",
          "Interact with LLM APIs for task completion",
          "Store and query memory in Qdrant"
        ]
      }
    },
    "tech_stack": {
      "languages": [
        {
          "name": "Python",
          "purpose": "Primary language for development",
          "key_features_used": [
            "Asynchronous programming",
            "Data serialization",
            "File operations",
            "Abstract base classes"
          ]
        }
      ],
      "frameworks": [
        {
          "name": "FastAPI",
          "purpose": "Building APIs",
          "key_features_used": [
            "Asynchronous request handling",
            "Creating REST endpoints"
          ]
        },
        {
          "name": "Playwright",
          "purpose": "Automated browser testing and interaction",
          "key_features_used": [
            "Browser automation",
            "Web page interaction"
          ]
        },
        {
          "name": "aiohttp",
          "purpose": "Handling asynchronous HTTP requests",
          "key_features_used": [
            "Asynchronous HTTP handling",
            "Client sessions"
          ]
        },
        {
          "name": "BeautifulSoup",
          "purpose": "Web scraping and HTML parsing",
          "key_features_used": [
            "Parsing HTML",
            "Extracting data from web pages"
          ]
        },
        {
          "name": "Markdownify",
          "purpose": "Converting HTML to Markdown",
          "key_features_used": [
            "HTML to Markdown conversion"
          ]
        },
        {
          "name": "Uvicorn",
          "purpose": "ASGI server for FastAPI",
          "key_features_used": [
            "Serving FastAPI applications",
            "Asynchronous server handling"
          ]
        },
        {
          "name": "pytest",
          "purpose": "Testing framework",
          "key_features_used": [
            "Unit testing",
            "Test discovery"
          ]
        },
        {
          "name": "pandas",
          "purpose": "Data manipulation and analysis",
          "key_features_used": [
            "DataFrames",
            "CSV manipulation"
          ]
        },
        {
          "name": "click",
          "purpose": "Building command-line interfaces",
          "key_features_used": [
            "Command line argument parsing",
            "CLI tool creation"
          ]
        }
      ],
      "tools": [
        {
          "name": "Docker",
          "purpose": "Containerizing applications"
        },
        {
          "name": "Docker Compose",
          "purpose": "Managing multi-container Docker applications"
        },
        {
          "name": "Qdrant",
          "purpose": "Vector database for semantic search and recommendations"
        },
        {
          "name": "Ollama",
          "purpose": "Large Language Model management"
        }
      ]
    },
    "code_patterns": [
      {
        "name": "Asynchronous Programming",
        "description": "Using asyncio and other async libraries to perform non-blocking operations",
        "example_location": "core/agent.py, actions/web_interface.py"
      },
      {
        "name": "Factory Pattern",
        "description": "Abstract base class for creating different LLM providers",
        "example_location": "llm_providers/base_provider.py"
      },
      {
        "name": "Command Pattern",
        "description": "Managing actions in a centralized registry for execution",
        "example_location": "actions/action_registry.py"
      },
      {
        "name": "Decorator Pattern",
        "description": "Decorators for retry mechanisms and logging",
        "example_location": "core/task_manager.py"
      },
      {
        "name": "Configuration Management",
        "description": "Using JSON and YAML for configuration setup",
        "example_location": "config.json, fluen_config.yml"
      },
      {
        "name": "Dependency Injection",
        "description": "Injecting dependencies like LLM providers and database clients",
        "example_location": "core/agent.py, api/main.py"
      }
    ]
  }
}